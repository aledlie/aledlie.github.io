This file is a merged representation of the entire codebase, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
__init__.py
CFF2ToCFF.py
CFFToCFF2.py
README_ENHANCED.md
README.md
specializer.py
transforms.py
width.py
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="__init__.py">
"""cffLib: read/write Adobe CFF fonts

OpenType fonts with PostScript outlines embed a completely independent
font file in Adobe's *Compact Font Format*. So dealing with OpenType fonts
requires also dealing with CFF. This module allows you to read and write
fonts written in the CFF format.

In 2016, OpenType 1.8 introduced the `CFF2 <https://docs.microsoft.com/en-us/typography/opentype/spec/cff2>`_
format which, along with other changes, extended the CFF format to deal with
the demands of variable fonts. This module parses both original CFF and CFF2.

"""

from fontTools.misc import sstruct
from fontTools.misc import psCharStrings
from fontTools.misc.arrayTools import unionRect, intRect
from fontTools.misc.textTools import (
    bytechr,
    byteord,
    bytesjoin,
    tobytes,
    tostr,
    safeEval,
)
from fontTools.ttLib import TTFont
from fontTools.ttLib.tables.otBase import OTTableWriter
from fontTools.ttLib.tables.otBase import OTTableReader
from fontTools.ttLib.tables import otTables as ot
from io import BytesIO
import struct
import logging
import re

# mute cffLib debug messages when running ttx in verbose mode
DEBUG = logging.DEBUG - 1
log = logging.getLogger(__name__)

cffHeaderFormat = """
	major:   B
	minor:   B
	hdrSize: B
"""

maxStackLimit = 513
# maxstack operator has been deprecated. max stack is now always 513.


class CFFFontSet(object):
    """A CFF font "file" can contain more than one font, although this is
    extremely rare (and not allowed within OpenType fonts).

    This class is the entry point for parsing a CFF table. To actually
    manipulate the data inside the CFF font, you will want to access the
    ``CFFFontSet``'s :class:`TopDict` object. To do this, a ``CFFFontSet``
    object can either be treated as a dictionary (with appropriate
    ``keys()`` and ``values()`` methods) mapping font names to :class:`TopDict`
    objects, or as a list.

    .. code:: python

            from fontTools import ttLib
            tt = ttLib.TTFont("Tests/cffLib/data/LinLibertine_RBI.otf")
            tt["CFF "].cff
            # <fontTools.cffLib.CFFFontSet object at 0x101e24c90>
            tt["CFF "].cff[0] # Here's your actual font data
            # <fontTools.cffLib.TopDict object at 0x1020f1fd0>

    """

    def decompile(self, file, otFont, isCFF2=None):
        """Parse a binary CFF file into an internal representation. ``file``
        should be a file handle object. ``otFont`` is the top-level
        :py:class:`fontTools.ttLib.ttFont.TTFont` object containing this CFF file.

        If ``isCFF2`` is passed and set to ``True`` or ``False``, then the
        library makes an assertion that the CFF header is of the appropriate
        version.
        """

        self.otFont = otFont
        sstruct.unpack(cffHeaderFormat, file.read(3), self)
        if isCFF2 is not None:
            # called from ttLib: assert 'major' as read from file matches the
            # expected version
            expected_major = 2 if isCFF2 else 1
            if self.major != expected_major:
                raise ValueError(
                    "Invalid CFF 'major' version: expected %d, found %d"
                    % (expected_major, self.major)
                )
        else:
            # use 'major' version from file to determine if isCFF2
            assert self.major in (1, 2), "Unknown CFF format"
            isCFF2 = self.major == 2
        if not isCFF2:
            self.offSize = struct.unpack("B", file.read(1))[0]
            file.seek(self.hdrSize)
            self.fontNames = list(tostr(s) for s in Index(file, isCFF2=isCFF2))
            self.topDictIndex = TopDictIndex(file, isCFF2=isCFF2)
            self.strings = IndexedStrings(file)
        else:  # isCFF2
            self.topDictSize = struct.unpack(">H", file.read(2))[0]
            file.seek(self.hdrSize)
            self.fontNames = ["CFF2Font"]
            cff2GetGlyphOrder = otFont.getGlyphOrder
            # in CFF2, offsetSize is the size of the TopDict data.
            self.topDictIndex = TopDictIndex(
                file, cff2GetGlyphOrder, self.topDictSize, isCFF2=isCFF2
            )
            self.strings = None
        self.GlobalSubrs = GlobalSubrsIndex(file, isCFF2=isCFF2)
        self.topDictIndex.strings = self.strings
        self.topDictIndex.GlobalSubrs = self.GlobalSubrs

    def __len__(self):
        return len(self.fontNames)

    def keys(self):
        return list(self.fontNames)

    def values(self):
        return self.topDictIndex

    def __getitem__(self, nameOrIndex):
        """Return TopDict instance identified by name (str) or index (int
        or any object that implements `__index__`).
        """
        if hasattr(nameOrIndex, "__index__"):
            index = nameOrIndex.__index__()
        elif isinstance(nameOrIndex, str):
            name = nameOrIndex
            try:
                index = self.fontNames.index(name)
            except ValueError:
                raise KeyError(nameOrIndex)
        else:
            raise TypeError(nameOrIndex)
        return self.topDictIndex[index]

    def compile(self, file, otFont, isCFF2=None):
        """Write the object back into binary representation onto the given file.
        ``file`` should be a file handle object. ``otFont`` is the top-level
        :py:class:`fontTools.ttLib.ttFont.TTFont` object containing this CFF file.

        If ``isCFF2`` is passed and set to ``True`` or ``False``, then the
        library makes an assertion that the CFF header is of the appropriate
        version.
        """
        self.otFont = otFont
        if isCFF2 is not None:
            # called from ttLib: assert 'major' value matches expected version
            expected_major = 2 if isCFF2 else 1
            if self.major != expected_major:
                raise ValueError(
                    "Invalid CFF 'major' version: expected %d, found %d"
                    % (expected_major, self.major)
                )
        else:
            # use current 'major' value to determine output format
            assert self.major in (1, 2), "Unknown CFF format"
            isCFF2 = self.major == 2

        if otFont.recalcBBoxes and not isCFF2:
            for topDict in self.topDictIndex:
                topDict.recalcFontBBox()

        if not isCFF2:
            strings = IndexedStrings()
        else:
            strings = None
        writer = CFFWriter(isCFF2)
        topCompiler = self.topDictIndex.getCompiler(strings, self, isCFF2=isCFF2)
        if isCFF2:
            self.hdrSize = 5
            writer.add(sstruct.pack(cffHeaderFormat, self))
            # Note: topDictSize will most likely change in CFFWriter.toFile().
            self.topDictSize = topCompiler.getDataLength()
            writer.add(struct.pack(">H", self.topDictSize))
        else:
            self.hdrSize = 4
            self.offSize = 4  # will most likely change in CFFWriter.toFile().
            writer.add(sstruct.pack(cffHeaderFormat, self))
            writer.add(struct.pack("B", self.offSize))
        if not isCFF2:
            fontNames = Index()
            for name in self.fontNames:
                fontNames.append(name)
            writer.add(fontNames.getCompiler(strings, self, isCFF2=isCFF2))
        writer.add(topCompiler)
        if not isCFF2:
            writer.add(strings.getCompiler())
        writer.add(self.GlobalSubrs.getCompiler(strings, self, isCFF2=isCFF2))

        for topDict in self.topDictIndex:
            if not hasattr(topDict, "charset") or topDict.charset is None:
                charset = otFont.getGlyphOrder()
                topDict.charset = charset
        children = topCompiler.getChildren(strings)
        for child in children:
            writer.add(child)

        writer.toFile(file)

    def toXML(self, xmlWriter):
        """Write the object into XML representation onto the given
        :class:`fontTools.misc.xmlWriter.XMLWriter`.

        .. code:: python

                writer = xmlWriter.XMLWriter(sys.stdout)
                tt["CFF "].cff.toXML(writer)

        """

        xmlWriter.simpletag("major", value=self.major)
        xmlWriter.newline()
        xmlWriter.simpletag("minor", value=self.minor)
        xmlWriter.newline()
        for fontName in self.fontNames:
            xmlWriter.begintag("CFFFont", name=tostr(fontName))
            xmlWriter.newline()
            font = self[fontName]
            font.toXML(xmlWriter)
            xmlWriter.endtag("CFFFont")
            xmlWriter.newline()
        xmlWriter.newline()
        xmlWriter.begintag("GlobalSubrs")
        xmlWriter.newline()
        self.GlobalSubrs.toXML(xmlWriter)
        xmlWriter.endtag("GlobalSubrs")
        xmlWriter.newline()

    def fromXML(self, name, attrs, content, otFont=None):
        """Reads data from the XML element into the ``CFFFontSet`` object."""
        self.otFont = otFont

        # set defaults. These will be replaced if there are entries for them
        # in the XML file.
        if not hasattr(self, "major"):
            self.major = 1
        if not hasattr(self, "minor"):
            self.minor = 0

        if name == "CFFFont":
            if self.major == 1:
                if not hasattr(self, "offSize"):
                    # this will be recalculated when the cff is compiled.
                    self.offSize = 4
                if not hasattr(self, "hdrSize"):
                    self.hdrSize = 4
                if not hasattr(self, "GlobalSubrs"):
                    self.GlobalSubrs = GlobalSubrsIndex()
                if not hasattr(self, "fontNames"):
                    self.fontNames = []
                    self.topDictIndex = TopDictIndex()
                fontName = attrs["name"]
                self.fontNames.append(fontName)
                topDict = TopDict(GlobalSubrs=self.GlobalSubrs)
                topDict.charset = None  # gets filled in later
            elif self.major == 2:
                if not hasattr(self, "hdrSize"):
                    self.hdrSize = 5
                if not hasattr(self, "GlobalSubrs"):
                    self.GlobalSubrs = GlobalSubrsIndex()
                if not hasattr(self, "fontNames"):
                    self.fontNames = ["CFF2Font"]
                cff2GetGlyphOrder = self.otFont.getGlyphOrder
                topDict = TopDict(
                    GlobalSubrs=self.GlobalSubrs, cff2GetGlyphOrder=cff2GetGlyphOrder
                )
                self.topDictIndex = TopDictIndex(None, cff2GetGlyphOrder)
            self.topDictIndex.append(topDict)
            for element in content:
                if isinstance(element, str):
                    continue
                name, attrs, content = element
                topDict.fromXML(name, attrs, content)

            if hasattr(topDict, "VarStore") and topDict.FDArray[0].vstore is None:
                fdArray = topDict.FDArray
                for fontDict in fdArray:
                    if hasattr(fontDict, "Private"):
                        fontDict.Private.vstore = topDict.VarStore

        elif name == "GlobalSubrs":
            subrCharStringClass = psCharStrings.T2CharString
            if not hasattr(self, "GlobalSubrs"):
                self.GlobalSubrs = GlobalSubrsIndex()
            for element in content:
                if isinstance(element, str):
                    continue
                name, attrs, content = element
                subr = subrCharStringClass()
                subr.fromXML(name, attrs, content)
                self.GlobalSubrs.append(subr)
        elif name == "major":
            self.major = int(attrs["value"])
        elif name == "minor":
            self.minor = int(attrs["value"])

    def convertCFFToCFF2(self, otFont):
        from .CFFToCFF2 import _convertCFFToCFF2

        _convertCFFToCFF2(self, otFont)

    def convertCFF2ToCFF(self, otFont):
        from .CFF2ToCFF import _convertCFF2ToCFF

        _convertCFF2ToCFF(self, otFont)

    def desubroutinize(self):
        from .transforms import desubroutinize

        desubroutinize(self)

    def remove_hints(self):
        from .transforms import remove_hints

        remove_hints(self)

    def remove_unused_subroutines(self):
        from .transforms import remove_unused_subroutines

        remove_unused_subroutines(self)


class CFFWriter(object):
    """Helper class for serializing CFF data to binary. Used by
    :meth:`CFFFontSet.compile`."""

    def __init__(self, isCFF2):
        self.data = []
        self.isCFF2 = isCFF2

    def add(self, table):
        self.data.append(table)

    def toFile(self, file):
        lastPosList = None
        count = 1
        while True:
            log.log(DEBUG, "CFFWriter.toFile() iteration: %d", count)
            count = count + 1
            pos = 0
            posList = [pos]
            for item in self.data:
                if hasattr(item, "getDataLength"):
                    endPos = pos + item.getDataLength()
                    if isinstance(item, TopDictIndexCompiler) and item.isCFF2:
                        self.topDictSize = item.getDataLength()
                else:
                    endPos = pos + len(item)
                if hasattr(item, "setPos"):
                    item.setPos(pos, endPos)
                pos = endPos
                posList.append(pos)
            if posList == lastPosList:
                break
            lastPosList = posList
        log.log(DEBUG, "CFFWriter.toFile() writing to file.")
        begin = file.tell()
        if self.isCFF2:
            self.data[1] = struct.pack(">H", self.topDictSize)
        else:
            self.offSize = calcOffSize(lastPosList[-1])
            self.data[1] = struct.pack("B", self.offSize)
        posList = [0]
        for item in self.data:
            if hasattr(item, "toFile"):
                item.toFile(file)
            else:
                file.write(item)
            posList.append(file.tell() - begin)
        assert posList == lastPosList


def calcOffSize(largestOffset):
    if largestOffset < 0x100:
        offSize = 1
    elif largestOffset < 0x10000:
        offSize = 2
    elif largestOffset < 0x1000000:
        offSize = 3
    else:
        offSize = 4
    return offSize


class IndexCompiler(object):
    """Base class for writing CFF `INDEX data <https://docs.microsoft.com/en-us/typography/opentype/spec/cff2#5-index-data>`_
    to binary."""

    def __init__(self, items, strings, parent, isCFF2=None):
        if isCFF2 is None and hasattr(parent, "isCFF2"):
            isCFF2 = parent.isCFF2
            assert isCFF2 is not None
        self.isCFF2 = isCFF2
        self.items = self.getItems(items, strings)
        self.parent = parent

    def getItems(self, items, strings):
        return items

    def getOffsets(self):
        # An empty INDEX contains only the count field.
        if self.items:
            pos = 1
            offsets = [pos]
            for item in self.items:
                if hasattr(item, "getDataLength"):
                    pos = pos + item.getDataLength()
                else:
                    pos = pos + len(item)
                offsets.append(pos)
        else:
            offsets = []
        return offsets

    def getDataLength(self):
        if self.isCFF2:
            countSize = 4
        else:
            countSize = 2

        if self.items:
            lastOffset = self.getOffsets()[-1]
            offSize = calcOffSize(lastOffset)
            dataLength = (
                countSize
                + 1  # count
                + (len(self.items) + 1) * offSize  # offSize
                + lastOffset  # the offsets
                - 1  # size of object data
            )
        else:
            # count. For empty INDEX tables, this is the only entry.
            dataLength = countSize

        return dataLength

    def toFile(self, file):
        offsets = self.getOffsets()
        if self.isCFF2:
            writeCard32(file, len(self.items))
        else:
            writeCard16(file, len(self.items))
        # An empty INDEX contains only the count field.
        if self.items:
            offSize = calcOffSize(offsets[-1])
            writeCard8(file, offSize)
            offSize = -offSize
            pack = struct.pack
            for offset in offsets:
                binOffset = pack(">l", offset)[offSize:]
                assert len(binOffset) == -offSize
                file.write(binOffset)
            for item in self.items:
                if hasattr(item, "toFile"):
                    item.toFile(file)
                else:
                    data = tobytes(item, encoding="latin1")
                    file.write(data)


class IndexedStringsCompiler(IndexCompiler):
    def getItems(self, items, strings):
        return items.strings


class TopDictIndexCompiler(IndexCompiler):
    """Helper class for writing the TopDict to binary."""

    def getItems(self, items, strings):
        out = []
        for item in items:
            out.append(item.getCompiler(strings, self))
        return out

    def getChildren(self, strings):
        children = []
        for topDict in self.items:
            children.extend(topDict.getChildren(strings))
        return children

    def getOffsets(self):
        if self.isCFF2:
            offsets = [0, self.items[0].getDataLength()]
            return offsets
        else:
            return super(TopDictIndexCompiler, self).getOffsets()

    def getDataLength(self):
        if self.isCFF2:
            dataLength = self.items[0].getDataLength()
            return dataLength
        else:
            return super(TopDictIndexCompiler, self).getDataLength()

    def toFile(self, file):
        if self.isCFF2:
            self.items[0].toFile(file)
        else:
            super(TopDictIndexCompiler, self).toFile(file)


class FDArrayIndexCompiler(IndexCompiler):
    """Helper class for writing the
    `Font DICT INDEX <https://docs.microsoft.com/en-us/typography/opentype/spec/cff2#10-font-dict-index-font-dicts-and-fdselect>`_
    to binary."""

    def getItems(self, items, strings):
        out = []
        for item in items:
            out.append(item.getCompiler(strings, self))
        return out

    def getChildren(self, strings):
        children = []
        for fontDict in self.items:
            children.extend(fontDict.getChildren(strings))
        return children

    def toFile(self, file):
        offsets = self.getOffsets()
        if self.isCFF2:
            writeCard32(file, len(self.items))
        else:
            writeCard16(file, len(self.items))
        offSize = calcOffSize(offsets[-1])
        writeCard8(file, offSize)
        offSize = -offSize
        pack = struct.pack
        for offset in offsets:
            binOffset = pack(">l", offset)[offSize:]
            assert len(binOffset) == -offSize
            file.write(binOffset)
        for item in self.items:
            if hasattr(item, "toFile"):
                item.toFile(file)
            else:
                file.write(item)

    def setPos(self, pos, endPos):
        self.parent.rawDict["FDArray"] = pos


class GlobalSubrsCompiler(IndexCompiler):
    """Helper class for writing the `global subroutine INDEX <https://docs.microsoft.com/en-us/typography/opentype/spec/cff2#9-local-and-global-subr-indexes>`_
    to binary."""

    def getItems(self, items, strings):
        out = []
        for cs in items:
            cs.compile(self.isCFF2)
            out.append(cs.bytecode)
        return out


class SubrsCompiler(GlobalSubrsCompiler):
    """Helper class for writing the `local subroutine INDEX <https://docs.microsoft.com/en-us/typography/opentype/spec/cff2#9-local-and-global-subr-indexes>`_
    to binary."""

    def setPos(self, pos, endPos):
        offset = pos - self.parent.pos
        self.parent.rawDict["Subrs"] = offset


class CharStringsCompiler(GlobalSubrsCompiler):
    """Helper class for writing the `CharStrings INDEX <https://docs.microsoft.com/en-us/typography/opentype/spec/cff2#9-local-and-global-subr-indexes>`_
    to binary."""

    def getItems(self, items, strings):
        out = []
        for cs in items:
            cs.compile(self.isCFF2)
            out.append(cs.bytecode)
        return out

    def setPos(self, pos, endPos):
        self.parent.rawDict["CharStrings"] = pos


class Index(object):
    """This class represents what the CFF spec calls an INDEX (an array of
    variable-sized objects). `Index` items can be addressed and set using
    Python list indexing."""

    compilerClass = IndexCompiler

    def __init__(self, file=None, isCFF2=None):
        self.items = []
        self.offsets = offsets = []
        name = self.__class__.__name__
        if file is None:
            return
        self._isCFF2 = isCFF2
        log.log(DEBUG, "loading %s at %s", name, file.tell())
        self.file = file
        if isCFF2:
            count = readCard32(file)
        else:
            count = readCard16(file)
        if count == 0:
            return
        self.items = [None] * count
        offSize = readCard8(file)
        log.log(DEBUG, "    index count: %s offSize: %s", count, offSize)
        assert offSize <= 4, "offSize too large: %s" % offSize
        pad = b"\0" * (4 - offSize)
        for index in range(count + 1):
            chunk = file.read(offSize)
            chunk = pad + chunk
            (offset,) = struct.unpack(">L", chunk)
            offsets.append(int(offset))
        self.offsetBase = file.tell() - 1
        file.seek(self.offsetBase + offsets[-1])  # pretend we've read the whole lot
        log.log(DEBUG, "    end of %s at %s", name, file.tell())

    def __len__(self):
        return len(self.items)

    def __getitem__(self, index):
        item = self.items[index]
        if item is not None:
            return item
        offset = self.offsets[index] + self.offsetBase
        size = self.offsets[index + 1] - self.offsets[index]
        file = self.file
        file.seek(offset)
        data = file.read(size)
        assert len(data) == size
        item = self.produceItem(index, data, file, offset)
        self.items[index] = item
        return item

    def __setitem__(self, index, item):
        self.items[index] = item

    def produceItem(self, index, data, file, offset):
        return data

    def append(self, item):
        """Add an item to an INDEX."""
        self.items.append(item)

    def getCompiler(self, strings, parent, isCFF2=None):
        return self.compilerClass(self, strings, parent, isCFF2=isCFF2)

    def clear(self):
        """Empty the INDEX."""
        del self.items[:]


class GlobalSubrsIndex(Index):
    """This index contains all the global subroutines in the font. A global
    subroutine is a set of ``CharString`` data which is accessible to any
    glyph in the font, and are used to store repeated instructions - for
    example, components may be encoded as global subroutines, but so could
    hinting instructions.

    Remember that when interpreting a ``callgsubr`` instruction (or indeed
    a ``callsubr`` instruction) that you will need to add the "subroutine
    number bias" to number given:

    .. code:: python

            tt = ttLib.TTFont("Almendra-Bold.otf")
            u = tt["CFF "].cff[0].CharStrings["udieresis"]
            u.decompile()

            u.toXML(XMLWriter(sys.stdout))
            # <some stuff>
            # -64 callgsubr <-- Subroutine which implements the dieresis mark
            # <other stuff>

            tt["CFF "].cff[0].GlobalSubrs[-64] # <-- WRONG
            # <T2CharString (bytecode) at 103451d10>

            tt["CFF "].cff[0].GlobalSubrs[-64 + 107] # <-- RIGHT
            # <T2CharString (source) at 103451390>

    ("The bias applied depends on the number of subrs (gsubrs). If the number of
    subrs (gsubrs) is less than 1240, the bias is 107. Otherwise if it is less
    than 33900, it is 1131; otherwise it is 32768.",
    `Subroutine Operators <https://docs.microsoft.com/en-us/typography/opentype/otspec180/cff2charstr#section4.4>`)
    """

    compilerClass = GlobalSubrsCompiler
    subrClass = psCharStrings.T2CharString
    charStringClass = psCharStrings.T2CharString

    def __init__(
        self,
        file=None,
        globalSubrs=None,
        private=None,
        fdSelect=None,
        fdArray=None,
        isCFF2=None,
    ):
        super(GlobalSubrsIndex, self).__init__(file, isCFF2=isCFF2)
        self.globalSubrs = globalSubrs
        self.private = private
        if fdSelect:
            self.fdSelect = fdSelect
        if fdArray:
            self.fdArray = fdArray

    def produceItem(self, index, data, file, offset):
        if self.private is not None:
            private = self.private
        elif hasattr(self, "fdArray") and self.fdArray is not None:
            if hasattr(self, "fdSelect") and self.fdSelect is not None:
                fdIndex = self.fdSelect[index]
            else:
                fdIndex = 0
            private = self.fdArray[fdIndex].Private
        else:
            private = None
        return self.subrClass(data, private=private, globalSubrs=self.globalSubrs)

    def toXML(self, xmlWriter):
        """Write the subroutines index into XML representation onto the given
        :class:`fontTools.misc.xmlWriter.XMLWriter`.

        .. code:: python

                writer = xmlWriter.XMLWriter(sys.stdout)
                tt["CFF "].cff[0].GlobalSubrs.toXML(writer)

        """
        xmlWriter.comment(
            "The 'index' attribute is only for humans; " "it is ignored when parsed."
        )
        xmlWriter.newline()
        for i in range(len(self)):
            subr = self[i]
            if subr.needsDecompilation():
                xmlWriter.begintag("CharString", index=i, raw=1)
            else:
                xmlWriter.begintag("CharString", index=i)
            xmlWriter.newline()
            subr.toXML(xmlWriter)
            xmlWriter.endtag("CharString")
            xmlWriter.newline()

    def fromXML(self, name, attrs, content):
        if name != "CharString":
            return
        subr = self.subrClass()
        subr.fromXML(name, attrs, content)
        self.append(subr)

    def getItemAndSelector(self, index):
        sel = None
        if hasattr(self, "fdSelect"):
            sel = self.fdSelect[index]
        return self[index], sel


class SubrsIndex(GlobalSubrsIndex):
    """This index contains a glyph's local subroutines. A local subroutine is a
    private set of ``CharString`` data which is accessible only to the glyph to
    which the index is attached."""

    compilerClass = SubrsCompiler


class TopDictIndex(Index):
    """This index represents the array of ``TopDict`` structures in the font
    (again, usually only one entry is present). Hence the following calls are
    equivalent:

    .. code:: python

            tt["CFF "].cff[0]
            # <fontTools.cffLib.TopDict object at 0x102ed6e50>
            tt["CFF "].cff.topDictIndex[0]
            # <fontTools.cffLib.TopDict object at 0x102ed6e50>

    """

    compilerClass = TopDictIndexCompiler

    def __init__(self, file=None, cff2GetGlyphOrder=None, topSize=0, isCFF2=None):
        self.cff2GetGlyphOrder = cff2GetGlyphOrder
        if file is not None and isCFF2:
            self._isCFF2 = isCFF2
            self.items = []
            name = self.__class__.__name__
            log.log(DEBUG, "loading %s at %s", name, file.tell())
            self.file = file
            count = 1
            self.items = [None] * count
            self.offsets = [0, topSize]
            self.offsetBase = file.tell()
            # pretend we've read the whole lot
            file.seek(self.offsetBase + topSize)
            log.log(DEBUG, "    end of %s at %s", name, file.tell())
        else:
            super(TopDictIndex, self).__init__(file, isCFF2=isCFF2)

    def produceItem(self, index, data, file, offset):
        top = TopDict(
            self.strings,
            file,
            offset,
            self.GlobalSubrs,
            self.cff2GetGlyphOrder,
            isCFF2=self._isCFF2,
        )
        top.decompile(data)
        return top

    def toXML(self, xmlWriter):
        for i in range(len(self)):
            xmlWriter.begintag("FontDict", index=i)
            xmlWriter.newline()
            self[i].toXML(xmlWriter)
            xmlWriter.endtag("FontDict")
            xmlWriter.newline()


class FDArrayIndex(Index):
    compilerClass = FDArrayIndexCompiler

    def toXML(self, xmlWriter):
        for i in range(len(self)):
            xmlWriter.begintag("FontDict", index=i)
            xmlWriter.newline()
            self[i].toXML(xmlWriter)
            xmlWriter.endtag("FontDict")
            xmlWriter.newline()

    def produceItem(self, index, data, file, offset):
        fontDict = FontDict(
            self.strings,
            file,
            offset,
            self.GlobalSubrs,
            isCFF2=self._isCFF2,
            vstore=self.vstore,
        )
        fontDict.decompile(data)
        return fontDict

    def fromXML(self, name, attrs, content):
        if name != "FontDict":
            return
        fontDict = FontDict()
        for element in content:
            if isinstance(element, str):
                continue
            name, attrs, content = element
            fontDict.fromXML(name, attrs, content)
        self.append(fontDict)


class VarStoreData(object):
    def __init__(self, file=None, otVarStore=None):
        self.file = file
        self.data = None
        self.otVarStore = otVarStore
        self.font = TTFont()  # dummy font for the decompile function.

    def decompile(self):
        if self.file:
            # read data in from file. Assume position is correct.
            length = readCard16(self.file)
            # https://github.com/fonttools/fonttools/issues/3673
            if length == 65535:
                self.data = self.file.read()
            else:
                self.data = self.file.read(length)
            globalState = {}
            reader = OTTableReader(self.data, globalState)
            self.otVarStore = ot.VarStore()
            self.otVarStore.decompile(reader, self.font)
            self.data = None
        return self

    def compile(self):
        writer = OTTableWriter()
        self.otVarStore.compile(writer, self.font)
        # Note that this omits the initial Card16 length from the CFF2
        # VarStore data block
        self.data = writer.getAllData()

    def writeXML(self, xmlWriter, name):
        self.otVarStore.toXML(xmlWriter, self.font)

    def xmlRead(self, name, attrs, content, parent):
        self.otVarStore = ot.VarStore()
        for element in content:
            if isinstance(element, tuple):
                name, attrs, content = element
                self.otVarStore.fromXML(name, attrs, content, self.font)
            else:
                pass
        return None

    def __len__(self):
        return len(self.data)

    def getNumRegions(self, vsIndex):
        if vsIndex is None:
            vsIndex = 0
        varData = self.otVarStore.VarData[vsIndex]
        numRegions = varData.VarRegionCount
        return numRegions


class FDSelect(object):
    def __init__(self, file=None, numGlyphs=None, format=None):
        if file:
            # read data in from file
            self.format = readCard8(file)
            if self.format == 0:
                from array import array

                self.gidArray = array("B", file.read(numGlyphs)).tolist()
            elif self.format == 3:
                gidArray = [None] * numGlyphs
                nRanges = readCard16(file)
                fd = None
                prev = None
                for i in range(nRanges):
                    first = readCard16(file)
                    if prev is not None:
                        for glyphID in range(prev, first):
                            gidArray[glyphID] = fd
                    prev = first
                    fd = readCard8(file)
                if prev is not None:
                    first = readCard16(file)
                    for glyphID in range(prev, first):
                        gidArray[glyphID] = fd
                self.gidArray = gidArray
            elif self.format == 4:
                gidArray = [None] * numGlyphs
                nRanges = readCard32(file)
                fd = None
                prev = None
                for i in range(nRanges):
                    first = readCard32(file)
                    if prev is not None:
                        for glyphID in range(prev, first):
                            gidArray[glyphID] = fd
                    prev = first
                    fd = readCard16(file)
                if prev is not None:
                    first = readCard32(file)
                    for glyphID in range(prev, first):
                        gidArray[glyphID] = fd
                self.gidArray = gidArray
            else:
                assert False, "unsupported FDSelect format: %s" % format
        else:
            # reading from XML. Make empty gidArray, and leave format as passed in.
            # format is None will result in the smallest representation being used.
            self.format = format
            self.gidArray = []

    def __len__(self):
        return len(self.gidArray)

    def __getitem__(self, index):
        return self.gidArray[index]

    def __setitem__(self, index, fdSelectValue):
        self.gidArray[index] = fdSelectValue

    def append(self, fdSelectValue):
        self.gidArray.append(fdSelectValue)


class CharStrings(object):
    """The ``CharStrings`` in the font represent the instructions for drawing
    each glyph. This object presents a dictionary interface to the font's
    CharStrings, indexed by glyph name:

    .. code:: python

            tt["CFF "].cff[0].CharStrings["a"]
            # <T2CharString (bytecode) at 103451e90>

    See :class:`fontTools.misc.psCharStrings.T1CharString` and
    :class:`fontTools.misc.psCharStrings.T2CharString` for how to decompile,
    compile and interpret the glyph drawing instructions in the returned objects.

    """

    def __init__(
        self,
        file,
        charset,
        globalSubrs,
        private,
        fdSelect,
        fdArray,
        isCFF2=None,
        varStore=None,
    ):
        self.globalSubrs = globalSubrs
        self.varStore = varStore
        if file is not None:
            self.charStringsIndex = SubrsIndex(
                file, globalSubrs, private, fdSelect, fdArray, isCFF2=isCFF2
            )
            self.charStrings = charStrings = {}
            for i in range(len(charset)):
                charStrings[charset[i]] = i
            # read from OTF file: charStrings.values() are indices into
            # charStringsIndex.
            self.charStringsAreIndexed = 1
        else:
            self.charStrings = {}
            # read from ttx file: charStrings.values() are actual charstrings
            self.charStringsAreIndexed = 0
            self.private = private
            if fdSelect is not None:
                self.fdSelect = fdSelect
            if fdArray is not None:
                self.fdArray = fdArray

    def keys(self):
        return list(self.charStrings.keys())

    def values(self):
        if self.charStringsAreIndexed:
            return self.charStringsIndex
        else:
            return list(self.charStrings.values())

    def has_key(self, name):
        return name in self.charStrings

    __contains__ = has_key

    def __len__(self):
        return len(self.charStrings)

    def __getitem__(self, name):
        charString = self.charStrings[name]
        if self.charStringsAreIndexed:
            charString = self.charStringsIndex[charString]
        return charString

    def __setitem__(self, name, charString):
        if self.charStringsAreIndexed:
            index = self.charStrings[name]
            self.charStringsIndex[index] = charString
        else:
            self.charStrings[name] = charString

    def getItemAndSelector(self, name):
        if self.charStringsAreIndexed:
            index = self.charStrings[name]
            return self.charStringsIndex.getItemAndSelector(index)
        else:
            if hasattr(self, "fdArray"):
                if hasattr(self, "fdSelect"):
                    sel = self.charStrings[name].fdSelectIndex
                else:
                    sel = 0
            else:
                sel = None
            return self.charStrings[name], sel

    def toXML(self, xmlWriter):
        names = sorted(self.keys())
        for name in names:
            charStr, fdSelectIndex = self.getItemAndSelector(name)
            if charStr.needsDecompilation():
                raw = [("raw", 1)]
            else:
                raw = []
            if fdSelectIndex is None:
                xmlWriter.begintag("CharString", [("name", name)] + raw)
            else:
                xmlWriter.begintag(
                    "CharString",
                    [("name", name), ("fdSelectIndex", fdSelectIndex)] + raw,
                )
            xmlWriter.newline()
            charStr.toXML(xmlWriter)
            xmlWriter.endtag("CharString")
            xmlWriter.newline()

    def fromXML(self, name, attrs, content):
        for element in content:
            if isinstance(element, str):
                continue
            name, attrs, content = element
            if name != "CharString":
                continue
            fdID = -1
            if hasattr(self, "fdArray"):
                try:
                    fdID = safeEval(attrs["fdSelectIndex"])
                except KeyError:
                    fdID = 0
                private = self.fdArray[fdID].Private
            else:
                private = self.private

            glyphName = attrs["name"]
            charStringClass = psCharStrings.T2CharString
            charString = charStringClass(private=private, globalSubrs=self.globalSubrs)
            charString.fromXML(name, attrs, content)
            if fdID >= 0:
                charString.fdSelectIndex = fdID
            self[glyphName] = charString


def readCard8(file):
    return byteord(file.read(1))


def readCard16(file):
    (value,) = struct.unpack(">H", file.read(2))
    return value


def readCard32(file):
    (value,) = struct.unpack(">L", file.read(4))
    return value


def writeCard8(file, value):
    file.write(bytechr(value))


def writeCard16(file, value):
    file.write(struct.pack(">H", value))


def writeCard32(file, value):
    file.write(struct.pack(">L", value))


def packCard8(value):
    return bytechr(value)


def packCard16(value):
    return struct.pack(">H", value)


def packCard32(value):
    return struct.pack(">L", value)


def buildOperatorDict(table):
    d = {}
    for op, name, arg, default, conv in table:
        d[op] = (name, arg)
    return d


def buildOpcodeDict(table):
    d = {}
    for op, name, arg, default, conv in table:
        if isinstance(op, tuple):
            op = bytechr(op[0]) + bytechr(op[1])
        else:
            op = bytechr(op)
        d[name] = (op, arg)
    return d


def buildOrder(table):
    l = []
    for op, name, arg, default, conv in table:
        l.append(name)
    return l


def buildDefaults(table):
    d = {}
    for op, name, arg, default, conv in table:
        if default is not None:
            d[name] = default
    return d


def buildConverters(table):
    d = {}
    for op, name, arg, default, conv in table:
        d[name] = conv
    return d


class SimpleConverter(object):
    def read(self, parent, value):
        if not hasattr(parent, "file"):
            return self._read(parent, value)
        file = parent.file
        pos = file.tell()
        try:
            return self._read(parent, value)
        finally:
            file.seek(pos)

    def _read(self, parent, value):
        return value

    def write(self, parent, value):
        return value

    def xmlWrite(self, xmlWriter, name, value):
        xmlWriter.simpletag(name, value=value)
        xmlWriter.newline()

    def xmlRead(self, name, attrs, content, parent):
        return attrs["value"]


class ASCIIConverter(SimpleConverter):
    def _read(self, parent, value):
        return tostr(value, encoding="ascii")

    def write(self, parent, value):
        return tobytes(value, encoding="ascii")

    def xmlWrite(self, xmlWriter, name, value):
        xmlWriter.simpletag(name, value=tostr(value, encoding="ascii"))
        xmlWriter.newline()

    def xmlRead(self, name, attrs, content, parent):
        return tobytes(attrs["value"], encoding=("ascii"))


class Latin1Converter(SimpleConverter):
    def _read(self, parent, value):
        return tostr(value, encoding="latin1")

    def write(self, parent, value):
        return tobytes(value, encoding="latin1")

    def xmlWrite(self, xmlWriter, name, value):
        value = tostr(value, encoding="latin1")
        if name in ["Notice", "Copyright"]:
            value = re.sub(r"[\r\n]\s+", " ", value)
        xmlWriter.simpletag(name, value=value)
        xmlWriter.newline()

    def xmlRead(self, name, attrs, content, parent):
        return tobytes(attrs["value"], encoding=("latin1"))


def parseNum(s):
    try:
        value = int(s)
    except:
        value = float(s)
    return value


def parseBlendList(s):
    valueList = []
    for element in s:
        if isinstance(element, str):
            continue
        name, attrs, content = element
        blendList = attrs["value"].split()
        blendList = [eval(val) for val in blendList]
        valueList.append(blendList)
    if len(valueList) == 1:
        valueList = valueList[0]
    return valueList


class NumberConverter(SimpleConverter):
    def xmlWrite(self, xmlWriter, name, value):
        if isinstance(value, list):
            xmlWriter.begintag(name)
            xmlWriter.newline()
            xmlWriter.indent()
            blendValue = " ".join([str(val) for val in value])
            xmlWriter.simpletag(kBlendDictOpName, value=blendValue)
            xmlWriter.newline()
            xmlWriter.dedent()
            xmlWriter.endtag(name)
            xmlWriter.newline()
        else:
            xmlWriter.simpletag(name, value=value)
            xmlWriter.newline()

    def xmlRead(self, name, attrs, content, parent):
        valueString = attrs.get("value", None)
        if valueString is None:
            value = parseBlendList(content)
        else:
            value = parseNum(attrs["value"])
        return value


class ArrayConverter(SimpleConverter):
    def xmlWrite(self, xmlWriter, name, value):
        if value and isinstance(value[0], list):
            xmlWriter.begintag(name)
            xmlWriter.newline()
            xmlWriter.indent()
            for valueList in value:
                blendValue = " ".join([str(val) for val in valueList])
                xmlWriter.simpletag(kBlendDictOpName, value=blendValue)
                xmlWriter.newline()
            xmlWriter.dedent()
            xmlWriter.endtag(name)
            xmlWriter.newline()
        else:
            value = " ".join([str(val) for val in value])
            xmlWriter.simpletag(name, value=value)
            xmlWriter.newline()

    def xmlRead(self, name, attrs, content, parent):
        valueString = attrs.get("value", None)
        if valueString is None:
            valueList = parseBlendList(content)
        else:
            values = valueString.split()
            valueList = [parseNum(value) for value in values]
        return valueList


class TableConverter(SimpleConverter):
    def xmlWrite(self, xmlWriter, name, value):
        xmlWriter.begintag(name)
        xmlWriter.newline()
        value.toXML(xmlWriter)
        xmlWriter.endtag(name)
        xmlWriter.newline()

    def xmlRead(self, name, attrs, content, parent):
        ob = self.getClass()()
        for element in content:
            if isinstance(element, str):
                continue
            name, attrs, content = element
            ob.fromXML(name, attrs, content)
        return ob


class PrivateDictConverter(TableConverter):
    def getClass(self):
        return PrivateDict

    def _read(self, parent, value):
        size, offset = value
        file = parent.file
        isCFF2 = parent._isCFF2
        try:
            vstore = parent.vstore
        except AttributeError:
            vstore = None
        priv = PrivateDict(parent.strings, file, offset, isCFF2=isCFF2, vstore=vstore)
        file.seek(offset)
        data = file.read(size)
        assert len(data) == size
        priv.decompile(data)
        return priv

    def write(self, parent, value):
        return (0, 0)  # dummy value


class SubrsConverter(TableConverter):
    def getClass(self):
        return SubrsIndex

    def _read(self, parent, value):
        file = parent.file
        isCFF2 = parent._isCFF2
        file.seek(parent.offset + value)  # Offset(self)
        return SubrsIndex(file, isCFF2=isCFF2)

    def write(self, parent, value):
        return 0  # dummy value


class CharStringsConverter(TableConverter):
    def _read(self, parent, value):
        file = parent.file
        isCFF2 = parent._isCFF2
        charset = parent.charset
        varStore = getattr(parent, "VarStore", None)
        globalSubrs = parent.GlobalSubrs
        if hasattr(parent, "FDArray"):
            fdArray = parent.FDArray
            if hasattr(parent, "FDSelect"):
                fdSelect = parent.FDSelect
            else:
                fdSelect = None
            private = None
        else:
            fdSelect, fdArray = None, None
            private = parent.Private
        file.seek(value)  # Offset(0)
        charStrings = CharStrings(
            file,
            charset,
            globalSubrs,
            private,
            fdSelect,
            fdArray,
            isCFF2=isCFF2,
            varStore=varStore,
        )
        return charStrings

    def write(self, parent, value):
        return 0  # dummy value

    def xmlRead(self, name, attrs, content, parent):
        if hasattr(parent, "FDArray"):
            # if it is a CID-keyed font, then the private Dict is extracted from the
            # parent.FDArray
            fdArray = parent.FDArray
            if hasattr(parent, "FDSelect"):
                fdSelect = parent.FDSelect
            else:
                fdSelect = None
            private = None
        else:
            # if it is a name-keyed font, then the private dict is in the top dict,
            # and
            # there is no fdArray.
            private, fdSelect, fdArray = parent.Private, None, None
        charStrings = CharStrings(
            None,
            None,
            parent.GlobalSubrs,
            private,
            fdSelect,
            fdArray,
            varStore=getattr(parent, "VarStore", None),
        )
        charStrings.fromXML(name, attrs, content)
        return charStrings


class CharsetConverter(SimpleConverter):
    def _read(self, parent, value):
        isCID = hasattr(parent, "ROS")
        if value > 2:
            numGlyphs = parent.numGlyphs
            file = parent.file
            file.seek(value)
            log.log(DEBUG, "loading charset at %s", value)
            format = readCard8(file)
            if format == 0:
                charset = parseCharset0(numGlyphs, file, parent.strings, isCID)
            elif format == 1 or format == 2:
                charset = parseCharset(numGlyphs, file, parent.strings, isCID, format)
            else:
                raise NotImplementedError
            assert len(charset) == numGlyphs
            log.log(DEBUG, "    charset end at %s", file.tell())
            # make sure glyph names are unique
            allNames = {}
            newCharset = []
            for glyphName in charset:
                if glyphName in allNames:
                    # make up a new glyphName that's unique
                    n = allNames[glyphName]
                    names = set(allNames) | set(charset)
                    while (glyphName + "." + str(n)) in names:
                        n += 1
                    allNames[glyphName] = n + 1
                    glyphName = glyphName + "." + str(n)
                allNames[glyphName] = 1
                newCharset.append(glyphName)
            charset = newCharset
        else:  # offset == 0 -> no charset data.
            if isCID or "CharStrings" not in parent.rawDict:
                # We get here only when processing fontDicts from the FDArray of
                # CFF-CID fonts. Only the real topDict references the charset.
                assert value == 0
                charset = None
            elif value == 0:
                charset = cffISOAdobeStrings
            elif value == 1:
                charset = cffIExpertStrings
            elif value == 2:
                charset = cffExpertSubsetStrings
        if charset and (len(charset) != parent.numGlyphs):
            charset = charset[: parent.numGlyphs]
        return charset

    def write(self, parent, value):
        return 0  # dummy value

    def xmlWrite(self, xmlWriter, name, value):
        # XXX only write charset when not in OT/TTX context, where we
        # dump charset as a separate "GlyphOrder" table.
        # # xmlWriter.simpletag("charset")
        xmlWriter.comment("charset is dumped separately as the 'GlyphOrder' element")
        xmlWriter.newline()

    def xmlRead(self, name, attrs, content, parent):
        pass


class CharsetCompiler(object):
    def __init__(self, strings, charset, parent):
        assert charset[0] == ".notdef"
        isCID = hasattr(parent.dictObj, "ROS")
        data0 = packCharset0(charset, isCID, strings)
        data = packCharset(charset, isCID, strings)
        if len(data) < len(data0):
            self.data = data
        else:
            self.data = data0
        self.parent = parent

    def setPos(self, pos, endPos):
        self.parent.rawDict["charset"] = pos

    def getDataLength(self):
        return len(self.data)

    def toFile(self, file):
        file.write(self.data)


def getStdCharSet(charset):
    # check to see if we can use a predefined charset value.
    predefinedCharSetVal = None
    predefinedCharSets = [
        (cffISOAdobeStringCount, cffISOAdobeStrings, 0),
        (cffExpertStringCount, cffIExpertStrings, 1),
        (cffExpertSubsetStringCount, cffExpertSubsetStrings, 2),
    ]
    lcs = len(charset)
    for cnt, pcs, csv in predefinedCharSets:
        if predefinedCharSetVal is not None:
            break
        if lcs > cnt:
            continue
        predefinedCharSetVal = csv
        for i in range(lcs):
            if charset[i] != pcs[i]:
                predefinedCharSetVal = None
                break
    return predefinedCharSetVal


def getCIDfromName(name, strings):
    return int(name[3:])


def getSIDfromName(name, strings):
    return strings.getSID(name)


def packCharset0(charset, isCID, strings):
    fmt = 0
    data = [packCard8(fmt)]
    if isCID:
        getNameID = getCIDfromName
    else:
        getNameID = getSIDfromName

    for name in charset[1:]:
        data.append(packCard16(getNameID(name, strings)))
    return bytesjoin(data)


def packCharset(charset, isCID, strings):
    fmt = 1
    ranges = []
    first = None
    end = 0
    if isCID:
        getNameID = getCIDfromName
    else:
        getNameID = getSIDfromName

    for name in charset[1:]:
        SID = getNameID(name, strings)
        if first is None:
            first = SID
        elif end + 1 != SID:
            nLeft = end - first
            if nLeft > 255:
                fmt = 2
            ranges.append((first, nLeft))
            first = SID
        end = SID
    if end:
        nLeft = end - first
        if nLeft > 255:
            fmt = 2
        ranges.append((first, nLeft))

    data = [packCard8(fmt)]
    if fmt == 1:
        nLeftFunc = packCard8
    else:
        nLeftFunc = packCard16
    for first, nLeft in ranges:
        data.append(packCard16(first) + nLeftFunc(nLeft))
    return bytesjoin(data)


def parseCharset0(numGlyphs, file, strings, isCID):
    charset = [".notdef"]
    if isCID:
        for i in range(numGlyphs - 1):
            CID = readCard16(file)
            charset.append("cid" + str(CID).zfill(5))
    else:
        for i in range(numGlyphs - 1):
            SID = readCard16(file)
            charset.append(strings[SID])
    return charset


def parseCharset(numGlyphs, file, strings, isCID, fmt):
    charset = [".notdef"]
    count = 1
    if fmt == 1:
        nLeftFunc = readCard8
    else:
        nLeftFunc = readCard16
    while count < numGlyphs:
        first = readCard16(file)
        nLeft = nLeftFunc(file)
        if isCID:
            for CID in range(first, first + nLeft + 1):
                charset.append("cid" + str(CID).zfill(5))
        else:
            for SID in range(first, first + nLeft + 1):
                charset.append(strings[SID])
        count = count + nLeft + 1
    return charset


class EncodingCompiler(object):
    def __init__(self, strings, encoding, parent):
        assert not isinstance(encoding, str)
        data0 = packEncoding0(parent.dictObj.charset, encoding, parent.strings)
        data1 = packEncoding1(parent.dictObj.charset, encoding, parent.strings)
        if len(data0) < len(data1):
            self.data = data0
        else:
            self.data = data1
        self.parent = parent

    def setPos(self, pos, endPos):
        self.parent.rawDict["Encoding"] = pos

    def getDataLength(self):
        return len(self.data)

    def toFile(self, file):
        file.write(self.data)


class EncodingConverter(SimpleConverter):
    def _read(self, parent, value):
        if value == 0:
            return "StandardEncoding"
        elif value == 1:
            return "ExpertEncoding"
        # custom encoding at offset `value`
        assert value > 1
        file = parent.file
        file.seek(value)
        log.log(DEBUG, "loading Encoding at %s", value)
        fmt = readCard8(file)
        haveSupplement = bool(fmt & 0x80)
        fmt = fmt & 0x7F

        if fmt == 0:
            encoding = parseEncoding0(parent.charset, file)
        elif fmt == 1:
            encoding = parseEncoding1(parent.charset, file)
        else:
            raise ValueError(f"Unknown Encoding format: {fmt}")

        if haveSupplement:
            parseEncodingSupplement(file, encoding, parent.strings)

        return encoding

    def write(self, parent, value):
        if value == "StandardEncoding":
            return 0
        elif value == "ExpertEncoding":
            return 1
        return 0  # dummy value

    def xmlWrite(self, xmlWriter, name, value):
        if value in ("StandardEncoding", "ExpertEncoding"):
            xmlWriter.simpletag(name, name=value)
            xmlWriter.newline()
            return
        xmlWriter.begintag(name)
        xmlWriter.newline()
        for code in range(len(value)):
            glyphName = value[code]
            if glyphName != ".notdef":
                xmlWriter.simpletag("map", code=hex(code), name=glyphName)
                xmlWriter.newline()
        xmlWriter.endtag(name)
        xmlWriter.newline()

    def xmlRead(self, name, attrs, content, parent):
        if "name" in attrs:
            return attrs["name"]
        encoding = [".notdef"] * 256
        for element in content:
            if isinstance(element, str):
                continue
            name, attrs, content = element
            code = safeEval(attrs["code"])
            glyphName = attrs["name"]
            encoding[code] = glyphName
        return encoding


def readSID(file):
    """Read a String ID (SID)  2-byte unsigned integer."""
    data = file.read(2)
    if len(data) != 2:
        raise EOFError("Unexpected end of file while reading SID")
    return struct.unpack(">H", data)[0]  # big-endian uint16


def parseEncodingSupplement(file, encoding, strings):
    """
    Parse the CFF Encoding supplement data:
      - nSups: number of supplementary mappings
      - each mapping: (code, SID) pair
    and apply them to the `encoding` list in place.
    """
    nSups = readCard8(file)
    for _ in range(nSups):
        code = readCard8(file)
        sid = readSID(file)
        name = strings[sid]
        encoding[code] = name


def parseEncoding0(charset, file):
    """
    Format 0: simple list of codes.
    After reading the base table, optionally parse the supplement.
    """
    nCodes = readCard8(file)
    encoding = [".notdef"] * 256
    for glyphID in range(1, nCodes + 1):
        code = readCard8(file)
        if code != 0:
            encoding[code] = charset[glyphID]

    return encoding


def parseEncoding1(charset, file):
    """
    Format1: range-based encoding.
    After reading the base ranges, optionally parse the supplement.
    """
    nRanges = readCard8(file)
    encoding = [".notdef"] * 256
    glyphID = 1
    for _ in range(nRanges):
        code = readCard8(file)
        nLeft = readCard8(file)
        for _ in range(nLeft + 1):
            encoding[code] = charset[glyphID]
            code += 1
            glyphID += 1

    return encoding


def packEncoding0(charset, encoding, strings):
    fmt = 0
    m = {}
    for code in range(len(encoding)):
        name = encoding[code]
        if name != ".notdef":
            m[name] = code
    codes = []
    for name in charset[1:]:
        code = m.get(name)
        codes.append(code)

    while codes and codes[-1] is None:
        codes.pop()

    data = [packCard8(fmt), packCard8(len(codes))]
    for code in codes:
        if code is None:
            code = 0
        data.append(packCard8(code))
    return bytesjoin(data)


def packEncoding1(charset, encoding, strings):
    fmt = 1
    m = {}
    for code in range(len(encoding)):
        name = encoding[code]
        if name != ".notdef":
            m[name] = code
    ranges = []
    first = None
    end = 0
    for name in charset[1:]:
        code = m.get(name, -1)
        if first is None:
            first = code
        elif end + 1 != code:
            nLeft = end - first
            ranges.append((first, nLeft))
            first = code
        end = code
    nLeft = end - first
    ranges.append((first, nLeft))

    # remove unencoded glyphs at the end.
    while ranges and ranges[-1][0] == -1:
        ranges.pop()

    data = [packCard8(fmt), packCard8(len(ranges))]
    for first, nLeft in ranges:
        if first == -1:  # unencoded
            first = 0
        data.append(packCard8(first) + packCard8(nLeft))
    return bytesjoin(data)


class FDArrayConverter(TableConverter):
    def _read(self, parent, value):
        try:
            vstore = parent.VarStore
        except AttributeError:
            vstore = None
        file = parent.file
        isCFF2 = parent._isCFF2
        file.seek(value)
        fdArray = FDArrayIndex(file, isCFF2=isCFF2)
        fdArray.vstore = vstore
        fdArray.strings = parent.strings
        fdArray.GlobalSubrs = parent.GlobalSubrs
        return fdArray

    def write(self, parent, value):
        return 0  # dummy value

    def xmlRead(self, name, attrs, content, parent):
        fdArray = FDArrayIndex()
        for element in content:
            if isinstance(element, str):
                continue
            name, attrs, content = element
            fdArray.fromXML(name, attrs, content)
        return fdArray


class FDSelectConverter(SimpleConverter):
    def _read(self, parent, value):
        file = parent.file
        file.seek(value)
        fdSelect = FDSelect(file, parent.numGlyphs)
        return fdSelect

    def write(self, parent, value):
        return 0  # dummy value

    # The FDSelect glyph data is written out to XML in the charstring keys,
    # so we write out only the format selector
    def xmlWrite(self, xmlWriter, name, value):
        xmlWriter.simpletag(name, [("format", value.format)])
        xmlWriter.newline()

    def xmlRead(self, name, attrs, content, parent):
        fmt = safeEval(attrs["format"])
        file = None
        numGlyphs = None
        fdSelect = FDSelect(file, numGlyphs, fmt)
        return fdSelect


class VarStoreConverter(SimpleConverter):
    def _read(self, parent, value):
        file = parent.file
        file.seek(value)
        varStore = VarStoreData(file)
        varStore.decompile()
        return varStore

    def write(self, parent, value):
        return 0  # dummy value

    def xmlWrite(self, xmlWriter, name, value):
        value.writeXML(xmlWriter, name)

    def xmlRead(self, name, attrs, content, parent):
        varStore = VarStoreData()
        varStore.xmlRead(name, attrs, content, parent)
        return varStore


def packFDSelect0(fdSelectArray):
    fmt = 0
    data = [packCard8(fmt)]
    for index in fdSelectArray:
        data.append(packCard8(index))
    return bytesjoin(data)


def packFDSelect3(fdSelectArray):
    fmt = 3
    fdRanges = []
    lenArray = len(fdSelectArray)
    lastFDIndex = -1
    for i in range(lenArray):
        fdIndex = fdSelectArray[i]
        if lastFDIndex != fdIndex:
            fdRanges.append([i, fdIndex])
            lastFDIndex = fdIndex
    sentinelGID = i + 1

    data = [packCard8(fmt)]
    data.append(packCard16(len(fdRanges)))
    for fdRange in fdRanges:
        data.append(packCard16(fdRange[0]))
        data.append(packCard8(fdRange[1]))
    data.append(packCard16(sentinelGID))
    return bytesjoin(data)


def packFDSelect4(fdSelectArray):
    fmt = 4
    fdRanges = []
    lenArray = len(fdSelectArray)
    lastFDIndex = -1
    for i in range(lenArray):
        fdIndex = fdSelectArray[i]
        if lastFDIndex != fdIndex:
            fdRanges.append([i, fdIndex])
            lastFDIndex = fdIndex
    sentinelGID = i + 1

    data = [packCard8(fmt)]
    data.append(packCard32(len(fdRanges)))
    for fdRange in fdRanges:
        data.append(packCard32(fdRange[0]))
        data.append(packCard16(fdRange[1]))
    data.append(packCard32(sentinelGID))
    return bytesjoin(data)


class FDSelectCompiler(object):
    def __init__(self, fdSelect, parent):
        fmt = fdSelect.format
        fdSelectArray = fdSelect.gidArray
        if fmt == 0:
            self.data = packFDSelect0(fdSelectArray)
        elif fmt == 3:
            self.data = packFDSelect3(fdSelectArray)
        elif fmt == 4:
            self.data = packFDSelect4(fdSelectArray)
        else:
            # choose smaller of the two formats
            data0 = packFDSelect0(fdSelectArray)
            data3 = packFDSelect3(fdSelectArray)
            if len(data0) < len(data3):
                self.data = data0
                fdSelect.format = 0
            else:
                self.data = data3
                fdSelect.format = 3

        self.parent = parent

    def setPos(self, pos, endPos):
        self.parent.rawDict["FDSelect"] = pos

    def getDataLength(self):
        return len(self.data)

    def toFile(self, file):
        file.write(self.data)


class VarStoreCompiler(object):
    def __init__(self, varStoreData, parent):
        self.parent = parent
        if not varStoreData.data:
            varStoreData.compile()
        varStoreDataLen = min(0xFFFF, len(varStoreData.data))
        data = [packCard16(varStoreDataLen), varStoreData.data]
        self.data = bytesjoin(data)

    def setPos(self, pos, endPos):
        self.parent.rawDict["VarStore"] = pos

    def getDataLength(self):
        return len(self.data)

    def toFile(self, file):
        file.write(self.data)


class ROSConverter(SimpleConverter):
    def xmlWrite(self, xmlWriter, name, value):
        registry, order, supplement = value
        xmlWriter.simpletag(
            name,
            [
                ("Registry", tostr(registry)),
                ("Order", tostr(order)),
                ("Supplement", supplement),
            ],
        )
        xmlWriter.newline()

    def xmlRead(self, name, attrs, content, parent):
        return (attrs["Registry"], attrs["Order"], safeEval(attrs["Supplement"]))


topDictOperators = [
    # 	opcode		name			argument type	default	converter
    (25, "maxstack", "number", None, None),
    ((12, 30), "ROS", ("SID", "SID", "number"), None, ROSConverter()),
    ((12, 20), "SyntheticBase", "number", None, None),
    (0, "version", "SID", None, None),
    (1, "Notice", "SID", None, Latin1Converter()),
    ((12, 0), "Copyright", "SID", None, Latin1Converter()),
    (2, "FullName", "SID", None, Latin1Converter()),
    ((12, 38), "FontName", "SID", None, Latin1Converter()),
    (3, "FamilyName", "SID", None, Latin1Converter()),
    (4, "Weight", "SID", None, None),
    ((12, 1), "isFixedPitch", "number", 0, None),
    ((12, 2), "ItalicAngle", "number", 0, None),
    ((12, 3), "UnderlinePosition", "number", -100, None),
    ((12, 4), "UnderlineThickness", "number", 50, None),
    ((12, 5), "PaintType", "number", 0, None),
    ((12, 6), "CharstringType", "number", 2, None),
    ((12, 7), "FontMatrix", "array", [0.001, 0, 0, 0.001, 0, 0], None),
    (13, "UniqueID", "number", None, None),
    (5, "FontBBox", "array", [0, 0, 0, 0], None),
    ((12, 8), "StrokeWidth", "number", 0, None),
    (14, "XUID", "array", None, None),
    ((12, 21), "PostScript", "SID", None, None),
    ((12, 22), "BaseFontName", "SID", None, None),
    ((12, 23), "BaseFontBlend", "delta", None, None),
    ((12, 31), "CIDFontVersion", "number", 0, None),
    ((12, 32), "CIDFontRevision", "number", 0, None),
    ((12, 33), "CIDFontType", "number", 0, None),
    ((12, 34), "CIDCount", "number", 8720, None),
    (15, "charset", "number", None, CharsetConverter()),
    ((12, 35), "UIDBase", "number", None, None),
    (16, "Encoding", "number", 0, EncodingConverter()),
    (18, "Private", ("number", "number"), None, PrivateDictConverter()),
    ((12, 37), "FDSelect", "number", None, FDSelectConverter()),
    ((12, 36), "FDArray", "number", None, FDArrayConverter()),
    (17, "CharStrings", "number", None, CharStringsConverter()),
    (24, "VarStore", "number", None, VarStoreConverter()),
]

topDictOperators2 = [
    # 	opcode		name			argument type	default	converter
    (25, "maxstack", "number", None, None),
    ((12, 7), "FontMatrix", "array", [0.001, 0, 0, 0.001, 0, 0], None),
    ((12, 37), "FDSelect", "number", None, FDSelectConverter()),
    ((12, 36), "FDArray", "number", None, FDArrayConverter()),
    (17, "CharStrings", "number", None, CharStringsConverter()),
    (24, "VarStore", "number", None, VarStoreConverter()),
]

# Note! FDSelect and FDArray must both preceed CharStrings in the output XML build order,
# in order for the font to compile back from xml.

kBlendDictOpName = "blend"
blendOp = 23

privateDictOperators = [
    # 	opcode		name			argument type	default	converter
    (22, "vsindex", "number", None, None),
    (
        blendOp,
        kBlendDictOpName,
        "blendList",
        None,
        None,
    ),  # This is for reading to/from XML: it not written to CFF.
    (6, "BlueValues", "delta", None, None),
    (7, "OtherBlues", "delta", None, None),
    (8, "FamilyBlues", "delta", None, None),
    (9, "FamilyOtherBlues", "delta", None, None),
    ((12, 9), "BlueScale", "number", 0.039625, None),
    ((12, 10), "BlueShift", "number", 7, None),
    ((12, 11), "BlueFuzz", "number", 1, None),
    (10, "StdHW", "number", None, None),
    (11, "StdVW", "number", None, None),
    ((12, 12), "StemSnapH", "delta", None, None),
    ((12, 13), "StemSnapV", "delta", None, None),
    ((12, 14), "ForceBold", "number", 0, None),
    ((12, 15), "ForceBoldThreshold", "number", None, None),  # deprecated
    ((12, 16), "lenIV", "number", None, None),  # deprecated
    ((12, 17), "LanguageGroup", "number", 0, None),
    ((12, 18), "ExpansionFactor", "number", 0.06, None),
    ((12, 19), "initialRandomSeed", "number", 0, None),
    (20, "defaultWidthX", "number", 0, None),
    (21, "nominalWidthX", "number", 0, None),
    (19, "Subrs", "number", None, SubrsConverter()),
]

privateDictOperators2 = [
    # 	opcode		name			argument type	default	converter
    (22, "vsindex", "number", None, None),
    (
        blendOp,
        kBlendDictOpName,
        "blendList",
        None,
        None,
    ),  # This is for reading to/from XML: it not written to CFF.
    (6, "BlueValues", "delta", None, None),
    (7, "OtherBlues", "delta", None, None),
    (8, "FamilyBlues", "delta", None, None),
    (9, "FamilyOtherBlues", "delta", None, None),
    ((12, 9), "BlueScale", "number", 0.039625, None),
    ((12, 10), "BlueShift", "number", 7, None),
    ((12, 11), "BlueFuzz", "number", 1, None),
    (10, "StdHW", "number", None, None),
    (11, "StdVW", "number", None, None),
    ((12, 12), "StemSnapH", "delta", None, None),
    ((12, 13), "StemSnapV", "delta", None, None),
    ((12, 17), "LanguageGroup", "number", 0, None),
    ((12, 18), "ExpansionFactor", "number", 0.06, None),
    (19, "Subrs", "number", None, SubrsConverter()),
]


def addConverters(table):
    for i in range(len(table)):
        op, name, arg, default, conv = table[i]
        if conv is not None:
            continue
        if arg in ("delta", "array"):
            conv = ArrayConverter()
        elif arg == "number":
            conv = NumberConverter()
        elif arg == "SID":
            conv = ASCIIConverter()
        elif arg == "blendList":
            conv = None
        else:
            assert False
        table[i] = op, name, arg, default, conv


addConverters(privateDictOperators)
addConverters(topDictOperators)


class TopDictDecompiler(psCharStrings.DictDecompiler):
    operators = buildOperatorDict(topDictOperators)


class PrivateDictDecompiler(psCharStrings.DictDecompiler):
    operators = buildOperatorDict(privateDictOperators)


class DictCompiler(object):
    maxBlendStack = 0

    def __init__(self, dictObj, strings, parent, isCFF2=None):
        if strings:
            assert isinstance(strings, IndexedStrings)
        if isCFF2 is None and hasattr(parent, "isCFF2"):
            isCFF2 = parent.isCFF2
            assert isCFF2 is not None
        self.isCFF2 = isCFF2
        self.dictObj = dictObj
        self.strings = strings
        self.parent = parent
        rawDict = {}
        for name in dictObj.order:
            value = getattr(dictObj, name, None)
            if value is None:
                continue
            conv = dictObj.converters[name]
            value = conv.write(dictObj, value)
            if value == dictObj.defaults.get(name):
                continue
            rawDict[name] = value
        self.rawDict = rawDict

    def setPos(self, pos, endPos):
        pass

    def getDataLength(self):
        return len(self.compile("getDataLength"))

    def compile(self, reason):
        log.log(DEBUG, "-- compiling %s for %s", self.__class__.__name__, reason)
        rawDict = self.rawDict
        data = []
        for name in self.dictObj.order:
            value = rawDict.get(name)
            if value is None:
                continue
            op, argType = self.opcodes[name]
            if isinstance(argType, tuple):
                l = len(argType)
                assert len(value) == l, "value doesn't match arg type"
                for i in range(l):
                    arg = argType[i]
                    v = value[i]
                    arghandler = getattr(self, "arg_" + arg)
                    data.append(arghandler(v))
            else:
                arghandler = getattr(self, "arg_" + argType)
                data.append(arghandler(value))
            data.append(op)
        data = bytesjoin(data)
        return data

    def toFile(self, file):
        data = self.compile("toFile")
        file.write(data)

    def arg_number(self, num):
        if isinstance(num, list):
            data = [encodeNumber(val) for val in num]
            data.append(encodeNumber(1))
            data.append(bytechr(blendOp))
            datum = bytesjoin(data)
        else:
            datum = encodeNumber(num)
        return datum

    def arg_SID(self, s):
        return psCharStrings.encodeIntCFF(self.strings.getSID(s))

    def arg_array(self, value):
        data = []
        for num in value:
            data.append(self.arg_number(num))
        return bytesjoin(data)

    def arg_delta(self, value):
        if not value:
            return b""
        val0 = value[0]
        if isinstance(val0, list):
            data = self.arg_delta_blend(value)
        else:
            out = []
            last = 0
            for v in value:
                out.append(v - last)
                last = v
            data = []
            for num in out:
                data.append(encodeNumber(num))
        return bytesjoin(data)

    def arg_delta_blend(self, value):
        """A delta list with blend lists has to be *all* blend lists.

        The value is a list is arranged as follows::

                [
                        [V0, d0..dn]
                        [V1, d0..dn]
                        ...
                        [Vm, d0..dn]
                ]

        ``V`` is the absolute coordinate value from the default font, and ``d0-dn``
        are the delta values from the *n* regions. Each ``V`` is an absolute
        coordinate from the default font.

        We want to return a list::

                [
                        [v0, v1..vm]
                        [d0..dn]
                        ...
                        [d0..dn]
                        numBlends
                        blendOp
                ]

        where each ``v`` is relative to the previous default font value.
        """
        numMasters = len(value[0])
        numBlends = len(value)
        numStack = (numBlends * numMasters) + 1
        if numStack > self.maxBlendStack:
            # Figure out the max number of value we can blend
            # and divide this list up into chunks of that size.

            numBlendValues = int((self.maxBlendStack - 1) / numMasters)
            out = []
            while True:
                numVal = min(len(value), numBlendValues)
                if numVal == 0:
                    break
                valList = value[0:numVal]
                out1 = self.arg_delta_blend(valList)
                out.extend(out1)
                value = value[numVal:]
        else:
            firstList = [0] * numBlends
            deltaList = [None] * numBlends
            i = 0
            prevVal = 0
            while i < numBlends:
                # For PrivateDict BlueValues, the default font
                # values are absolute, not relative.
                # Must convert these back to relative coordinates
                # before writing to CFF2.
                defaultValue = value[i][0]
                firstList[i] = defaultValue - prevVal
                prevVal = defaultValue
                deltaList[i] = value[i][1:]
                i += 1

            relValueList = firstList
            for blendList in deltaList:
                relValueList.extend(blendList)
            out = [encodeNumber(val) for val in relValueList]
            out.append(encodeNumber(numBlends))
            out.append(bytechr(blendOp))
        return out


def encodeNumber(num):
    if isinstance(num, float):
        return psCharStrings.encodeFloat(num)
    else:
        return psCharStrings.encodeIntCFF(num)


class TopDictCompiler(DictCompiler):
    opcodes = buildOpcodeDict(topDictOperators)

    def getChildren(self, strings):
        isCFF2 = self.isCFF2
        children = []
        if self.dictObj.cff2GetGlyphOrder is None:
            if hasattr(self.dictObj, "charset") and self.dictObj.charset:
                if hasattr(self.dictObj, "ROS"):  # aka isCID
                    charsetCode = None
                else:
                    charsetCode = getStdCharSet(self.dictObj.charset)
                if charsetCode is None:
                    children.append(
                        CharsetCompiler(strings, self.dictObj.charset, self)
                    )
                else:
                    self.rawDict["charset"] = charsetCode
            if hasattr(self.dictObj, "Encoding") and self.dictObj.Encoding:
                encoding = self.dictObj.Encoding
                if not isinstance(encoding, str):
                    children.append(EncodingCompiler(strings, encoding, self))
        else:
            if hasattr(self.dictObj, "VarStore"):
                varStoreData = self.dictObj.VarStore
                varStoreComp = VarStoreCompiler(varStoreData, self)
                children.append(varStoreComp)
        if hasattr(self.dictObj, "FDSelect"):
            # I have not yet supported merging a ttx CFF-CID font, as there are
            # interesting issues about merging the FDArrays. Here I assume that
            # either the font was read from XML, and the FDSelect indices are all
            # in the charstring data, or the FDSelect array is already fully defined.
            fdSelect = self.dictObj.FDSelect
            # probably read in from XML; assume fdIndex in CharString data
            if len(fdSelect) == 0:
                charStrings = self.dictObj.CharStrings
                for name in self.dictObj.charset:
                    fdSelect.append(charStrings[name].fdSelectIndex)
            fdSelectComp = FDSelectCompiler(fdSelect, self)
            children.append(fdSelectComp)
        if hasattr(self.dictObj, "CharStrings"):
            items = []
            charStrings = self.dictObj.CharStrings
            for name in self.dictObj.charset:
                items.append(charStrings[name])
            charStringsComp = CharStringsCompiler(items, strings, self, isCFF2=isCFF2)
            children.append(charStringsComp)
        if hasattr(self.dictObj, "FDArray"):
            # I have not yet supported merging a ttx CFF-CID font, as there are
            # interesting issues about merging the FDArrays. Here I assume that the
            # FDArray info is correct and complete.
            fdArrayIndexComp = self.dictObj.FDArray.getCompiler(strings, self)
            children.append(fdArrayIndexComp)
            children.extend(fdArrayIndexComp.getChildren(strings))
        if hasattr(self.dictObj, "Private"):
            privComp = self.dictObj.Private.getCompiler(strings, self)
            children.append(privComp)
            children.extend(privComp.getChildren(strings))
        return children


class FontDictCompiler(DictCompiler):
    opcodes = buildOpcodeDict(topDictOperators)

    def __init__(self, dictObj, strings, parent, isCFF2=None):
        super(FontDictCompiler, self).__init__(dictObj, strings, parent, isCFF2=isCFF2)
        #
        # We now take some effort to detect if there were any key/value pairs
        # supplied that were ignored in the FontDict context, and issue a warning
        # for those cases.
        #
        ignoredNames = []
        dictObj = self.dictObj
        for name in sorted(set(dictObj.converters) - set(dictObj.order)):
            if name in dictObj.rawDict:
                # The font was directly read from binary. In this
                # case, we want to report *all* "useless" key/value
                # pairs that are in the font, not just the ones that
                # are different from the default.
                ignoredNames.append(name)
            else:
                # The font was probably read from a TTX file. We only
                # warn about keys whos value is not the default. The
                # ones that have the default value will not be written
                # to binary anyway.
                default = dictObj.defaults.get(name)
                if default is not None:
                    conv = dictObj.converters[name]
                    default = conv.read(dictObj, default)
                if getattr(dictObj, name, None) != default:
                    ignoredNames.append(name)
        if ignoredNames:
            log.warning(
                "Some CFF FDArray/FontDict keys were ignored upon compile: "
                + " ".join(sorted(ignoredNames))
            )

    def getChildren(self, strings):
        children = []
        if hasattr(self.dictObj, "Private"):
            privComp = self.dictObj.Private.getCompiler(strings, self)
            children.append(privComp)
            children.extend(privComp.getChildren(strings))
        return children


class PrivateDictCompiler(DictCompiler):
    maxBlendStack = maxStackLimit
    opcodes = buildOpcodeDict(privateDictOperators)

    def setPos(self, pos, endPos):
        size = endPos - pos
        self.parent.rawDict["Private"] = size, pos
        self.pos = pos

    def getChildren(self, strings):
        children = []
        if hasattr(self.dictObj, "Subrs"):
            children.append(self.dictObj.Subrs.getCompiler(strings, self))
        return children


class BaseDict(object):
    def __init__(self, strings=None, file=None, offset=None, isCFF2=None):
        assert (isCFF2 is None) == (file is None)
        self.rawDict = {}
        self.skipNames = []
        self.strings = strings
        if file is None:
            return
        self._isCFF2 = isCFF2
        self.file = file
        if offset is not None:
            log.log(DEBUG, "loading %s at %s", self.__class__.__name__, offset)
            self.offset = offset

    def decompile(self, data):
        log.log(DEBUG, "    length %s is %d", self.__class__.__name__, len(data))
        dec = self.decompilerClass(self.strings, self)
        dec.decompile(data)
        self.rawDict = dec.getDict()
        self.postDecompile()

    def postDecompile(self):
        pass

    def getCompiler(self, strings, parent, isCFF2=None):
        return self.compilerClass(self, strings, parent, isCFF2=isCFF2)

    def __getattr__(self, name):
        if name[:2] == name[-2:] == "__":
            # to make deepcopy() and pickle.load() work, we need to signal with
            # AttributeError that dunder methods like '__deepcopy__' or '__getstate__'
            # aren't implemented. For more details, see:
            # https://github.com/fonttools/fonttools/pull/1488
            raise AttributeError(name)
        value = self.rawDict.get(name, None)
        if value is None:
            value = self.defaults.get(name)
        if value is None:
            raise AttributeError(name)
        conv = self.converters[name]
        value = conv.read(self, value)
        setattr(self, name, value)
        return value

    def toXML(self, xmlWriter):
        for name in self.order:
            if name in self.skipNames:
                continue
            value = getattr(self, name, None)
            # XXX For "charset" we never skip calling xmlWrite even if the
            # value is None, so we always write the following XML comment:
            #
            # <!-- charset is dumped separately as the 'GlyphOrder' element -->
            #
            # Charset is None when 'CFF ' table is imported from XML into an
            # empty TTFont(). By writing this comment all the time, we obtain
            # the same XML output whether roundtripping XML-to-XML or
            # dumping binary-to-XML
            if value is None and name != "charset":
                continue
            conv = self.converters[name]
            conv.xmlWrite(xmlWriter, name, value)
        ignoredNames = set(self.rawDict) - set(self.order)
        if ignoredNames:
            xmlWriter.comment(
                "some keys were ignored: %s" % " ".join(sorted(ignoredNames))
            )
            xmlWriter.newline()

    def fromXML(self, name, attrs, content):
        conv = self.converters[name]
        value = conv.xmlRead(name, attrs, content, self)
        setattr(self, name, value)


class TopDict(BaseDict):
    """The ``TopDict`` represents the top-level dictionary holding font
    information. CFF2 tables contain a restricted set of top-level entries
    as described `here <https://docs.microsoft.com/en-us/typography/opentype/spec/cff2#7-top-dict-data>`_,
    but CFF tables may contain a wider range of information. This information
    can be accessed through attributes or through the dictionary returned
    through the ``rawDict`` property:

    .. code:: python

            font = tt["CFF "].cff[0]
            font.FamilyName
            # 'Linux Libertine O'
            font.rawDict["FamilyName"]
            # 'Linux Libertine O'

    More information is available in the CFF file's private dictionary, accessed
    via the ``Private`` property:

    .. code:: python

            tt["CFF "].cff[0].Private.BlueValues
            # [-15, 0, 515, 515, 666, 666]

    """

    defaults = buildDefaults(topDictOperators)
    converters = buildConverters(topDictOperators)
    compilerClass = TopDictCompiler
    order = buildOrder(topDictOperators)
    decompilerClass = TopDictDecompiler

    def __init__(
        self,
        strings=None,
        file=None,
        offset=None,
        GlobalSubrs=None,
        cff2GetGlyphOrder=None,
        isCFF2=None,
    ):
        super(TopDict, self).__init__(strings, file, offset, isCFF2=isCFF2)
        self.cff2GetGlyphOrder = cff2GetGlyphOrder
        self.GlobalSubrs = GlobalSubrs
        if isCFF2:
            self.defaults = buildDefaults(topDictOperators2)
            self.charset = cff2GetGlyphOrder()
            self.order = buildOrder(topDictOperators2)
        else:
            self.defaults = buildDefaults(topDictOperators)
            self.order = buildOrder(topDictOperators)

    def getGlyphOrder(self):
        """Returns a list of glyph names in the CFF font."""
        return self.charset

    def postDecompile(self):
        offset = self.rawDict.get("CharStrings")
        if offset is None:
            return
        # get the number of glyphs beforehand.
        self.file.seek(offset)
        if self._isCFF2:
            self.numGlyphs = readCard32(self.file)
        else:
            self.numGlyphs = readCard16(self.file)

    def toXML(self, xmlWriter):
        if hasattr(self, "CharStrings"):
            self.decompileAllCharStrings()
        if hasattr(self, "ROS"):
            self.skipNames = ["Encoding"]
        if not hasattr(self, "ROS") or not hasattr(self, "CharStrings"):
            # these values have default values, but I only want them to show up
            # in CID fonts.
            self.skipNames = [
                "CIDFontVersion",
                "CIDFontRevision",
                "CIDFontType",
                "CIDCount",
            ]
        BaseDict.toXML(self, xmlWriter)

    def decompileAllCharStrings(self):
        # Make sure that all the Private Dicts have been instantiated.
        for i, charString in enumerate(self.CharStrings.values()):
            try:
                charString.decompile()
            except:
                log.error("Error in charstring %s", i)
                raise

    def recalcFontBBox(self):
        fontBBox = None
        for charString in self.CharStrings.values():
            bounds = charString.calcBounds(self.CharStrings)
            if bounds is not None:
                if fontBBox is not None:
                    fontBBox = unionRect(fontBBox, bounds)
                else:
                    fontBBox = bounds

        if fontBBox is None:
            self.FontBBox = self.defaults["FontBBox"][:]
        else:
            self.FontBBox = list(intRect(fontBBox))


class FontDict(BaseDict):
    #
    # Since fonttools used to pass a lot of fields that are not relevant in the FDArray
    # FontDict, there are 'ttx' files in the wild that contain all these. These got in
    # the ttx files because fonttools writes explicit values for all the TopDict default
    # values. These are not actually illegal in the context of an FDArray FontDict - you
    # can legally, per spec, put any arbitrary key/value pair in a FontDict - but are
    # useless since current major company CFF interpreters ignore anything but the set
    # listed in this file. So, we just silently skip them. An exception is Weight: this
    # is not used by any interpreter, but some foundries have asked that this be
    # supported in FDArray FontDicts just to preserve information about the design when
    # the font is being inspected.
    #
    # On top of that, there are fonts out there that contain such useless FontDict values.
    #
    # By subclassing TopDict, we *allow* all key/values from TopDict, both when reading
    # from binary or when reading from XML, but by overriding `order` with a limited
    # list of names, we ensure that only the useful names ever get exported to XML and
    # ever get compiled into the binary font.
    #
    # We override compilerClass so we can warn about "useless" key/value pairs, either
    # from the original binary font or from TTX input.
    #
    # See:
    # - https://github.com/fonttools/fonttools/issues/740
    # - https://github.com/fonttools/fonttools/issues/601
    # - https://github.com/adobe-type-tools/afdko/issues/137
    #
    defaults = {}
    converters = buildConverters(topDictOperators)
    compilerClass = FontDictCompiler
    orderCFF = ["FontName", "FontMatrix", "Weight", "Private"]
    orderCFF2 = ["Private"]
    decompilerClass = TopDictDecompiler

    def __init__(
        self,
        strings=None,
        file=None,
        offset=None,
        GlobalSubrs=None,
        isCFF2=None,
        vstore=None,
    ):
        super(FontDict, self).__init__(strings, file, offset, isCFF2=isCFF2)
        self.vstore = vstore
        self.setCFF2(isCFF2)

    def setCFF2(self, isCFF2):
        # isCFF2 may be None.
        if isCFF2:
            self.order = self.orderCFF2
            self._isCFF2 = True
        else:
            self.order = self.orderCFF
            self._isCFF2 = False


class PrivateDict(BaseDict):
    defaults = buildDefaults(privateDictOperators)
    converters = buildConverters(privateDictOperators)
    order = buildOrder(privateDictOperators)
    decompilerClass = PrivateDictDecompiler
    compilerClass = PrivateDictCompiler

    def __init__(self, strings=None, file=None, offset=None, isCFF2=None, vstore=None):
        super(PrivateDict, self).__init__(strings, file, offset, isCFF2=isCFF2)
        self.vstore = vstore
        if isCFF2:
            self.defaults = buildDefaults(privateDictOperators2)
            self.order = buildOrder(privateDictOperators2)
            # Provide dummy values. This avoids needing to provide
            # an isCFF2 state in a lot of places.
            self.nominalWidthX = self.defaultWidthX = None
            self._isCFF2 = True
        else:
            self.defaults = buildDefaults(privateDictOperators)
            self.order = buildOrder(privateDictOperators)
            self._isCFF2 = False

    @property
    def in_cff2(self):
        return self._isCFF2

    def getNumRegions(self, vi=None):  # called from misc/psCharStrings.py
        # if getNumRegions is being called, we can assume that VarStore exists.
        if vi is None:
            if hasattr(self, "vsindex"):
                vi = self.vsindex
            else:
                vi = 0
        numRegions = self.vstore.getNumRegions(vi)
        return numRegions


class IndexedStrings(object):
    """SID -> string mapping."""

    def __init__(self, file=None):
        if file is None:
            strings = []
        else:
            strings = [tostr(s, encoding="latin1") for s in Index(file, isCFF2=False)]
        self.strings = strings

    def getCompiler(self):
        return IndexedStringsCompiler(self, None, self, isCFF2=False)

    def __len__(self):
        return len(self.strings)

    def __getitem__(self, SID):
        if SID < cffStandardStringCount:
            return cffStandardStrings[SID]
        else:
            return self.strings[SID - cffStandardStringCount]

    def getSID(self, s):
        if not hasattr(self, "stringMapping"):
            self.buildStringMapping()
        s = tostr(s, encoding="latin1")
        if s in cffStandardStringMapping:
            SID = cffStandardStringMapping[s]
        elif s in self.stringMapping:
            SID = self.stringMapping[s]
        else:
            SID = len(self.strings) + cffStandardStringCount
            self.strings.append(s)
            self.stringMapping[s] = SID
        return SID

    def getStrings(self):
        return self.strings

    def buildStringMapping(self):
        self.stringMapping = {}
        for index in range(len(self.strings)):
            self.stringMapping[self.strings[index]] = index + cffStandardStringCount


# The 391 Standard Strings as used in the CFF format.
# from Adobe Technical None #5176, version 1.0, 18 March 1998

cffStandardStrings = [
    ".notdef",
    "space",
    "exclam",
    "quotedbl",
    "numbersign",
    "dollar",
    "percent",
    "ampersand",
    "quoteright",
    "parenleft",
    "parenright",
    "asterisk",
    "plus",
    "comma",
    "hyphen",
    "period",
    "slash",
    "zero",
    "one",
    "two",
    "three",
    "four",
    "five",
    "six",
    "seven",
    "eight",
    "nine",
    "colon",
    "semicolon",
    "less",
    "equal",
    "greater",
    "question",
    "at",
    "A",
    "B",
    "C",
    "D",
    "E",
    "F",
    "G",
    "H",
    "I",
    "J",
    "K",
    "L",
    "M",
    "N",
    "O",
    "P",
    "Q",
    "R",
    "S",
    "T",
    "U",
    "V",
    "W",
    "X",
    "Y",
    "Z",
    "bracketleft",
    "backslash",
    "bracketright",
    "asciicircum",
    "underscore",
    "quoteleft",
    "a",
    "b",
    "c",
    "d",
    "e",
    "f",
    "g",
    "h",
    "i",
    "j",
    "k",
    "l",
    "m",
    "n",
    "o",
    "p",
    "q",
    "r",
    "s",
    "t",
    "u",
    "v",
    "w",
    "x",
    "y",
    "z",
    "braceleft",
    "bar",
    "braceright",
    "asciitilde",
    "exclamdown",
    "cent",
    "sterling",
    "fraction",
    "yen",
    "florin",
    "section",
    "currency",
    "quotesingle",
    "quotedblleft",
    "guillemotleft",
    "guilsinglleft",
    "guilsinglright",
    "fi",
    "fl",
    "endash",
    "dagger",
    "daggerdbl",
    "periodcentered",
    "paragraph",
    "bullet",
    "quotesinglbase",
    "quotedblbase",
    "quotedblright",
    "guillemotright",
    "ellipsis",
    "perthousand",
    "questiondown",
    "grave",
    "acute",
    "circumflex",
    "tilde",
    "macron",
    "breve",
    "dotaccent",
    "dieresis",
    "ring",
    "cedilla",
    "hungarumlaut",
    "ogonek",
    "caron",
    "emdash",
    "AE",
    "ordfeminine",
    "Lslash",
    "Oslash",
    "OE",
    "ordmasculine",
    "ae",
    "dotlessi",
    "lslash",
    "oslash",
    "oe",
    "germandbls",
    "onesuperior",
    "logicalnot",
    "mu",
    "trademark",
    "Eth",
    "onehalf",
    "plusminus",
    "Thorn",
    "onequarter",
    "divide",
    "brokenbar",
    "degree",
    "thorn",
    "threequarters",
    "twosuperior",
    "registered",
    "minus",
    "eth",
    "multiply",
    "threesuperior",
    "copyright",
    "Aacute",
    "Acircumflex",
    "Adieresis",
    "Agrave",
    "Aring",
    "Atilde",
    "Ccedilla",
    "Eacute",
    "Ecircumflex",
    "Edieresis",
    "Egrave",
    "Iacute",
    "Icircumflex",
    "Idieresis",
    "Igrave",
    "Ntilde",
    "Oacute",
    "Ocircumflex",
    "Odieresis",
    "Ograve",
    "Otilde",
    "Scaron",
    "Uacute",
    "Ucircumflex",
    "Udieresis",
    "Ugrave",
    "Yacute",
    "Ydieresis",
    "Zcaron",
    "aacute",
    "acircumflex",
    "adieresis",
    "agrave",
    "aring",
    "atilde",
    "ccedilla",
    "eacute",
    "ecircumflex",
    "edieresis",
    "egrave",
    "iacute",
    "icircumflex",
    "idieresis",
    "igrave",
    "ntilde",
    "oacute",
    "ocircumflex",
    "odieresis",
    "ograve",
    "otilde",
    "scaron",
    "uacute",
    "ucircumflex",
    "udieresis",
    "ugrave",
    "yacute",
    "ydieresis",
    "zcaron",
    "exclamsmall",
    "Hungarumlautsmall",
    "dollaroldstyle",
    "dollarsuperior",
    "ampersandsmall",
    "Acutesmall",
    "parenleftsuperior",
    "parenrightsuperior",
    "twodotenleader",
    "onedotenleader",
    "zerooldstyle",
    "oneoldstyle",
    "twooldstyle",
    "threeoldstyle",
    "fouroldstyle",
    "fiveoldstyle",
    "sixoldstyle",
    "sevenoldstyle",
    "eightoldstyle",
    "nineoldstyle",
    "commasuperior",
    "threequartersemdash",
    "periodsuperior",
    "questionsmall",
    "asuperior",
    "bsuperior",
    "centsuperior",
    "dsuperior",
    "esuperior",
    "isuperior",
    "lsuperior",
    "msuperior",
    "nsuperior",
    "osuperior",
    "rsuperior",
    "ssuperior",
    "tsuperior",
    "ff",
    "ffi",
    "ffl",
    "parenleftinferior",
    "parenrightinferior",
    "Circumflexsmall",
    "hyphensuperior",
    "Gravesmall",
    "Asmall",
    "Bsmall",
    "Csmall",
    "Dsmall",
    "Esmall",
    "Fsmall",
    "Gsmall",
    "Hsmall",
    "Ismall",
    "Jsmall",
    "Ksmall",
    "Lsmall",
    "Msmall",
    "Nsmall",
    "Osmall",
    "Psmall",
    "Qsmall",
    "Rsmall",
    "Ssmall",
    "Tsmall",
    "Usmall",
    "Vsmall",
    "Wsmall",
    "Xsmall",
    "Ysmall",
    "Zsmall",
    "colonmonetary",
    "onefitted",
    "rupiah",
    "Tildesmall",
    "exclamdownsmall",
    "centoldstyle",
    "Lslashsmall",
    "Scaronsmall",
    "Zcaronsmall",
    "Dieresissmall",
    "Brevesmall",
    "Caronsmall",
    "Dotaccentsmall",
    "Macronsmall",
    "figuredash",
    "hypheninferior",
    "Ogoneksmall",
    "Ringsmall",
    "Cedillasmall",
    "questiondownsmall",
    "oneeighth",
    "threeeighths",
    "fiveeighths",
    "seveneighths",
    "onethird",
    "twothirds",
    "zerosuperior",
    "foursuperior",
    "fivesuperior",
    "sixsuperior",
    "sevensuperior",
    "eightsuperior",
    "ninesuperior",
    "zeroinferior",
    "oneinferior",
    "twoinferior",
    "threeinferior",
    "fourinferior",
    "fiveinferior",
    "sixinferior",
    "seveninferior",
    "eightinferior",
    "nineinferior",
    "centinferior",
    "dollarinferior",
    "periodinferior",
    "commainferior",
    "Agravesmall",
    "Aacutesmall",
    "Acircumflexsmall",
    "Atildesmall",
    "Adieresissmall",
    "Aringsmall",
    "AEsmall",
    "Ccedillasmall",
    "Egravesmall",
    "Eacutesmall",
    "Ecircumflexsmall",
    "Edieresissmall",
    "Igravesmall",
    "Iacutesmall",
    "Icircumflexsmall",
    "Idieresissmall",
    "Ethsmall",
    "Ntildesmall",
    "Ogravesmall",
    "Oacutesmall",
    "Ocircumflexsmall",
    "Otildesmall",
    "Odieresissmall",
    "OEsmall",
    "Oslashsmall",
    "Ugravesmall",
    "Uacutesmall",
    "Ucircumflexsmall",
    "Udieresissmall",
    "Yacutesmall",
    "Thornsmall",
    "Ydieresissmall",
    "001.000",
    "001.001",
    "001.002",
    "001.003",
    "Black",
    "Bold",
    "Book",
    "Light",
    "Medium",
    "Regular",
    "Roman",
    "Semibold",
]

cffStandardStringCount = 391
assert len(cffStandardStrings) == cffStandardStringCount
# build reverse mapping
cffStandardStringMapping = {}
for _i in range(cffStandardStringCount):
    cffStandardStringMapping[cffStandardStrings[_i]] = _i

cffISOAdobeStrings = [
    ".notdef",
    "space",
    "exclam",
    "quotedbl",
    "numbersign",
    "dollar",
    "percent",
    "ampersand",
    "quoteright",
    "parenleft",
    "parenright",
    "asterisk",
    "plus",
    "comma",
    "hyphen",
    "period",
    "slash",
    "zero",
    "one",
    "two",
    "three",
    "four",
    "five",
    "six",
    "seven",
    "eight",
    "nine",
    "colon",
    "semicolon",
    "less",
    "equal",
    "greater",
    "question",
    "at",
    "A",
    "B",
    "C",
    "D",
    "E",
    "F",
    "G",
    "H",
    "I",
    "J",
    "K",
    "L",
    "M",
    "N",
    "O",
    "P",
    "Q",
    "R",
    "S",
    "T",
    "U",
    "V",
    "W",
    "X",
    "Y",
    "Z",
    "bracketleft",
    "backslash",
    "bracketright",
    "asciicircum",
    "underscore",
    "quoteleft",
    "a",
    "b",
    "c",
    "d",
    "e",
    "f",
    "g",
    "h",
    "i",
    "j",
    "k",
    "l",
    "m",
    "n",
    "o",
    "p",
    "q",
    "r",
    "s",
    "t",
    "u",
    "v",
    "w",
    "x",
    "y",
    "z",
    "braceleft",
    "bar",
    "braceright",
    "asciitilde",
    "exclamdown",
    "cent",
    "sterling",
    "fraction",
    "yen",
    "florin",
    "section",
    "currency",
    "quotesingle",
    "quotedblleft",
    "guillemotleft",
    "guilsinglleft",
    "guilsinglright",
    "fi",
    "fl",
    "endash",
    "dagger",
    "daggerdbl",
    "periodcentered",
    "paragraph",
    "bullet",
    "quotesinglbase",
    "quotedblbase",
    "quotedblright",
    "guillemotright",
    "ellipsis",
    "perthousand",
    "questiondown",
    "grave",
    "acute",
    "circumflex",
    "tilde",
    "macron",
    "breve",
    "dotaccent",
    "dieresis",
    "ring",
    "cedilla",
    "hungarumlaut",
    "ogonek",
    "caron",
    "emdash",
    "AE",
    "ordfeminine",
    "Lslash",
    "Oslash",
    "OE",
    "ordmasculine",
    "ae",
    "dotlessi",
    "lslash",
    "oslash",
    "oe",
    "germandbls",
    "onesuperior",
    "logicalnot",
    "mu",
    "trademark",
    "Eth",
    "onehalf",
    "plusminus",
    "Thorn",
    "onequarter",
    "divide",
    "brokenbar",
    "degree",
    "thorn",
    "threequarters",
    "twosuperior",
    "registered",
    "minus",
    "eth",
    "multiply",
    "threesuperior",
    "copyright",
    "Aacute",
    "Acircumflex",
    "Adieresis",
    "Agrave",
    "Aring",
    "Atilde",
    "Ccedilla",
    "Eacute",
    "Ecircumflex",
    "Edieresis",
    "Egrave",
    "Iacute",
    "Icircumflex",
    "Idieresis",
    "Igrave",
    "Ntilde",
    "Oacute",
    "Ocircumflex",
    "Odieresis",
    "Ograve",
    "Otilde",
    "Scaron",
    "Uacute",
    "Ucircumflex",
    "Udieresis",
    "Ugrave",
    "Yacute",
    "Ydieresis",
    "Zcaron",
    "aacute",
    "acircumflex",
    "adieresis",
    "agrave",
    "aring",
    "atilde",
    "ccedilla",
    "eacute",
    "ecircumflex",
    "edieresis",
    "egrave",
    "iacute",
    "icircumflex",
    "idieresis",
    "igrave",
    "ntilde",
    "oacute",
    "ocircumflex",
    "odieresis",
    "ograve",
    "otilde",
    "scaron",
    "uacute",
    "ucircumflex",
    "udieresis",
    "ugrave",
    "yacute",
    "ydieresis",
    "zcaron",
]

cffISOAdobeStringCount = 229
assert len(cffISOAdobeStrings) == cffISOAdobeStringCount

cffIExpertStrings = [
    ".notdef",
    "space",
    "exclamsmall",
    "Hungarumlautsmall",
    "dollaroldstyle",
    "dollarsuperior",
    "ampersandsmall",
    "Acutesmall",
    "parenleftsuperior",
    "parenrightsuperior",
    "twodotenleader",
    "onedotenleader",
    "comma",
    "hyphen",
    "period",
    "fraction",
    "zerooldstyle",
    "oneoldstyle",
    "twooldstyle",
    "threeoldstyle",
    "fouroldstyle",
    "fiveoldstyle",
    "sixoldstyle",
    "sevenoldstyle",
    "eightoldstyle",
    "nineoldstyle",
    "colon",
    "semicolon",
    "commasuperior",
    "threequartersemdash",
    "periodsuperior",
    "questionsmall",
    "asuperior",
    "bsuperior",
    "centsuperior",
    "dsuperior",
    "esuperior",
    "isuperior",
    "lsuperior",
    "msuperior",
    "nsuperior",
    "osuperior",
    "rsuperior",
    "ssuperior",
    "tsuperior",
    "ff",
    "fi",
    "fl",
    "ffi",
    "ffl",
    "parenleftinferior",
    "parenrightinferior",
    "Circumflexsmall",
    "hyphensuperior",
    "Gravesmall",
    "Asmall",
    "Bsmall",
    "Csmall",
    "Dsmall",
    "Esmall",
    "Fsmall",
    "Gsmall",
    "Hsmall",
    "Ismall",
    "Jsmall",
    "Ksmall",
    "Lsmall",
    "Msmall",
    "Nsmall",
    "Osmall",
    "Psmall",
    "Qsmall",
    "Rsmall",
    "Ssmall",
    "Tsmall",
    "Usmall",
    "Vsmall",
    "Wsmall",
    "Xsmall",
    "Ysmall",
    "Zsmall",
    "colonmonetary",
    "onefitted",
    "rupiah",
    "Tildesmall",
    "exclamdownsmall",
    "centoldstyle",
    "Lslashsmall",
    "Scaronsmall",
    "Zcaronsmall",
    "Dieresissmall",
    "Brevesmall",
    "Caronsmall",
    "Dotaccentsmall",
    "Macronsmall",
    "figuredash",
    "hypheninferior",
    "Ogoneksmall",
    "Ringsmall",
    "Cedillasmall",
    "onequarter",
    "onehalf",
    "threequarters",
    "questiondownsmall",
    "oneeighth",
    "threeeighths",
    "fiveeighths",
    "seveneighths",
    "onethird",
    "twothirds",
    "zerosuperior",
    "onesuperior",
    "twosuperior",
    "threesuperior",
    "foursuperior",
    "fivesuperior",
    "sixsuperior",
    "sevensuperior",
    "eightsuperior",
    "ninesuperior",
    "zeroinferior",
    "oneinferior",
    "twoinferior",
    "threeinferior",
    "fourinferior",
    "fiveinferior",
    "sixinferior",
    "seveninferior",
    "eightinferior",
    "nineinferior",
    "centinferior",
    "dollarinferior",
    "periodinferior",
    "commainferior",
    "Agravesmall",
    "Aacutesmall",
    "Acircumflexsmall",
    "Atildesmall",
    "Adieresissmall",
    "Aringsmall",
    "AEsmall",
    "Ccedillasmall",
    "Egravesmall",
    "Eacutesmall",
    "Ecircumflexsmall",
    "Edieresissmall",
    "Igravesmall",
    "Iacutesmall",
    "Icircumflexsmall",
    "Idieresissmall",
    "Ethsmall",
    "Ntildesmall",
    "Ogravesmall",
    "Oacutesmall",
    "Ocircumflexsmall",
    "Otildesmall",
    "Odieresissmall",
    "OEsmall",
    "Oslashsmall",
    "Ugravesmall",
    "Uacutesmall",
    "Ucircumflexsmall",
    "Udieresissmall",
    "Yacutesmall",
    "Thornsmall",
    "Ydieresissmall",
]

cffExpertStringCount = 166
assert len(cffIExpertStrings) == cffExpertStringCount

cffExpertSubsetStrings = [
    ".notdef",
    "space",
    "dollaroldstyle",
    "dollarsuperior",
    "parenleftsuperior",
    "parenrightsuperior",
    "twodotenleader",
    "onedotenleader",
    "comma",
    "hyphen",
    "period",
    "fraction",
    "zerooldstyle",
    "oneoldstyle",
    "twooldstyle",
    "threeoldstyle",
    "fouroldstyle",
    "fiveoldstyle",
    "sixoldstyle",
    "sevenoldstyle",
    "eightoldstyle",
    "nineoldstyle",
    "colon",
    "semicolon",
    "commasuperior",
    "threequartersemdash",
    "periodsuperior",
    "asuperior",
    "bsuperior",
    "centsuperior",
    "dsuperior",
    "esuperior",
    "isuperior",
    "lsuperior",
    "msuperior",
    "nsuperior",
    "osuperior",
    "rsuperior",
    "ssuperior",
    "tsuperior",
    "ff",
    "fi",
    "fl",
    "ffi",
    "ffl",
    "parenleftinferior",
    "parenrightinferior",
    "hyphensuperior",
    "colonmonetary",
    "onefitted",
    "rupiah",
    "centoldstyle",
    "figuredash",
    "hypheninferior",
    "onequarter",
    "onehalf",
    "threequarters",
    "oneeighth",
    "threeeighths",
    "fiveeighths",
    "seveneighths",
    "onethird",
    "twothirds",
    "zerosuperior",
    "onesuperior",
    "twosuperior",
    "threesuperior",
    "foursuperior",
    "fivesuperior",
    "sixsuperior",
    "sevensuperior",
    "eightsuperior",
    "ninesuperior",
    "zeroinferior",
    "oneinferior",
    "twoinferior",
    "threeinferior",
    "fourinferior",
    "fiveinferior",
    "sixinferior",
    "seveninferior",
    "eightinferior",
    "nineinferior",
    "centinferior",
    "dollarinferior",
    "periodinferior",
    "commainferior",
]

cffExpertSubsetStringCount = 87
assert len(cffExpertSubsetStrings) == cffExpertSubsetStringCount
</file>

<file path="CFF2ToCFF.py">
"""CFF2 to CFF converter."""

from fontTools.ttLib import TTFont, newTable
from fontTools.misc.cliTools import makeOutputFileName
from fontTools.misc.psCharStrings import T2StackUseExtractor
from fontTools.cffLib import (
    TopDictIndex,
    buildOrder,
    buildDefaults,
    topDictOperators,
    privateDictOperators,
    FDSelect,
)
from .transforms import desubroutinizeCharString
from .specializer import specializeProgram
from .width import optimizeWidths
from collections import defaultdict
import logging


__all__ = ["convertCFF2ToCFF", "main"]


log = logging.getLogger("fontTools.cffLib")


def _convertCFF2ToCFF(cff, otFont):
    """Converts this object from CFF2 format to CFF format. This conversion
    is done 'in-place'. The conversion cannot be reversed.

    The CFF2 font cannot be variable. (TODO Accept those and convert to the
    default instance?)

    This assumes a decompiled CFF2 table. (i.e. that the object has been
    filled via :meth:`decompile` and e.g. not loaded from XML.)"""

    cff.major = 1

    topDictData = TopDictIndex(None)
    for item in cff.topDictIndex:
        # Iterate over, such that all are decompiled
        item.cff2GetGlyphOrder = None
        topDictData.append(item)
    cff.topDictIndex = topDictData
    topDict = topDictData[0]

    if hasattr(topDict, "VarStore"):
        raise ValueError("Variable CFF2 font cannot be converted to CFF format.")

    opOrder = buildOrder(topDictOperators)
    topDict.order = opOrder
    for key in topDict.rawDict.keys():
        if key not in opOrder:
            del topDict.rawDict[key]
            if hasattr(topDict, key):
                delattr(topDict, key)

    charStrings = topDict.CharStrings

    fdArray = topDict.FDArray
    if not hasattr(topDict, "FDSelect"):
        # FDSelect is optional in CFF2, but required in CFF.
        fdSelect = topDict.FDSelect = FDSelect()
        fdSelect.gidArray = [0] * len(charStrings.charStrings)

    defaults = buildDefaults(privateDictOperators)
    order = buildOrder(privateDictOperators)
    for fd in fdArray:
        fd.setCFF2(False)
        privateDict = fd.Private
        privateDict.order = order
        for key in order:
            if key not in privateDict.rawDict and key in defaults:
                privateDict.rawDict[key] = defaults[key]
        for key in privateDict.rawDict.keys():
            if key not in order:
                del privateDict.rawDict[key]
                if hasattr(privateDict, key):
                    delattr(privateDict, key)

    # Add ending operators
    for cs in charStrings.values():
        cs.decompile()
        cs.program.append("endchar")
    for subrSets in [cff.GlobalSubrs] + [
        getattr(fd.Private, "Subrs", []) for fd in fdArray
    ]:
        for cs in subrSets:
            cs.program.append("return")

    # Add (optimal) width to CharStrings that need it.
    widths = defaultdict(list)
    metrics = otFont["hmtx"].metrics
    for glyphName in charStrings.keys():
        cs, fdIndex = charStrings.getItemAndSelector(glyphName)
        if fdIndex == None:
            fdIndex = 0
        widths[fdIndex].append(metrics[glyphName][0])
    for fdIndex, widthList in widths.items():
        bestDefault, bestNominal = optimizeWidths(widthList)
        private = fdArray[fdIndex].Private
        private.defaultWidthX = bestDefault
        private.nominalWidthX = bestNominal
    for glyphName in charStrings.keys():
        cs, fdIndex = charStrings.getItemAndSelector(glyphName)
        if fdIndex == None:
            fdIndex = 0
        private = fdArray[fdIndex].Private
        width = metrics[glyphName][0]
        if width != private.defaultWidthX:
            cs.program.insert(0, width - private.nominalWidthX)

    # Handle stack use since stack-depth is lower in CFF than in CFF2.
    for glyphName in charStrings.keys():
        cs, fdIndex = charStrings.getItemAndSelector(glyphName)
        if fdIndex is None:
            fdIndex = 0
        private = fdArray[fdIndex].Private
        extractor = T2StackUseExtractor(
            getattr(private, "Subrs", []), cff.GlobalSubrs, private=private
        )
        stackUse = extractor.execute(cs)
        if stackUse > 48:  # CFF stack depth is 48
            desubroutinizeCharString(cs)
            cs.program = specializeProgram(cs.program)

    # Unused subroutines are still in CFF2 (ie. lacking 'return' operator)
    # because they were not decompiled when we added the 'return'.
    # Moreover, some used subroutines may have become unused after the
    # stack-use fixup. So we remove all unused subroutines now.
    cff.remove_unused_subroutines()

    mapping = {
        name: ("cid" + str(n).zfill(5) if n else ".notdef")
        for n, name in enumerate(topDict.charset)
    }
    topDict.charset = [
        "cid" + str(n).zfill(5) if n else ".notdef" for n in range(len(topDict.charset))
    ]
    charStrings.charStrings = {
        mapping[name]: v for name, v in charStrings.charStrings.items()
    }

    topDict.ROS = ("Adobe", "Identity", 0)


def convertCFF2ToCFF(font, *, updatePostTable=True):
    if "CFF2" not in font:
        raise ValueError("Input font does not contain a CFF2 table.")
    cff = font["CFF2"].cff
    _convertCFF2ToCFF(cff, font)
    del font["CFF2"]
    table = font["CFF "] = newTable("CFF ")
    table.cff = cff

    if updatePostTable and "post" in font:
        # Only version supported for fonts with CFF table is 0x00030000 not 0x20000
        post = font["post"]
        if post.formatType == 2.0:
            post.formatType = 3.0


def main(args=None):
    """Convert CFF2 OTF font to CFF OTF font"""
    if args is None:
        import sys

        args = sys.argv[1:]

    import argparse

    parser = argparse.ArgumentParser(
        "fonttools cffLib.CFF2ToCFF",
        description="Convert a non-variable CFF2 font to CFF.",
    )
    parser.add_argument(
        "input", metavar="INPUT.ttf", help="Input OTF file with CFF table."
    )
    parser.add_argument(
        "-o",
        "--output",
        metavar="OUTPUT.ttf",
        default=None,
        help="Output instance OTF file (default: INPUT-CFF2.ttf).",
    )
    parser.add_argument(
        "--no-recalc-timestamp",
        dest="recalc_timestamp",
        action="store_false",
        help="Don't set the output font's timestamp to the current time.",
    )
    loggingGroup = parser.add_mutually_exclusive_group(required=False)
    loggingGroup.add_argument(
        "-v", "--verbose", action="store_true", help="Run more verbosely."
    )
    loggingGroup.add_argument(
        "-q", "--quiet", action="store_true", help="Turn verbosity off."
    )
    options = parser.parse_args(args)

    from fontTools import configLogger

    configLogger(
        level=("DEBUG" if options.verbose else "ERROR" if options.quiet else "INFO")
    )

    import os

    infile = options.input
    if not os.path.isfile(infile):
        parser.error("No such file '{}'".format(infile))

    outfile = (
        makeOutputFileName(infile, overWrite=True, suffix="-CFF")
        if not options.output
        else options.output
    )

    font = TTFont(infile, recalcTimestamp=options.recalc_timestamp, recalcBBoxes=False)

    convertCFF2ToCFF(font)

    log.info(
        "Saving %s",
        outfile,
    )
    font.save(outfile)


if __name__ == "__main__":
    import sys

    sys.exit(main(sys.argv[1:]))
</file>

<file path="CFFToCFF2.py">
"""CFF to CFF2 converter."""

from fontTools.ttLib import TTFont, newTable
from fontTools.misc.cliTools import makeOutputFileName
from fontTools.misc.psCharStrings import T2WidthExtractor
from fontTools.cffLib import (
    TopDictIndex,
    FDArrayIndex,
    FontDict,
    buildOrder,
    topDictOperators,
    privateDictOperators,
    topDictOperators2,
    privateDictOperators2,
)
from io import BytesIO
import logging

__all__ = ["convertCFFToCFF2", "main"]


log = logging.getLogger("fontTools.cffLib")


class _NominalWidthUsedError(Exception):
    def __add__(self, other):
        raise self

    def __radd__(self, other):
        raise self


def _convertCFFToCFF2(cff, otFont):
    """Converts this object from CFF format to CFF2 format. This conversion
    is done 'in-place'. The conversion cannot be reversed.

    This assumes a decompiled CFF table. (i.e. that the object has been
    filled via :meth:`decompile` and e.g. not loaded from XML.)"""

    # Clean up T2CharStrings

    topDict = cff.topDictIndex[0]
    fdArray = topDict.FDArray if hasattr(topDict, "FDArray") else None
    charStrings = topDict.CharStrings
    globalSubrs = cff.GlobalSubrs
    localSubrs = (
        [getattr(fd.Private, "Subrs", []) for fd in fdArray]
        if fdArray
        else (
            [topDict.Private.Subrs]
            if hasattr(topDict, "Private") and hasattr(topDict.Private, "Subrs")
            else []
        )
    )

    for glyphName in charStrings.keys():
        cs, fdIndex = charStrings.getItemAndSelector(glyphName)
        cs.decompile()

    # Clean up subroutines first
    for subrs in [globalSubrs] + localSubrs:
        for subr in subrs:
            program = subr.program
            i = j = len(program)
            try:
                i = program.index("return")
            except ValueError:
                pass
            try:
                j = program.index("endchar")
            except ValueError:
                pass
            program[min(i, j) :] = []

    # Clean up glyph charstrings
    removeUnusedSubrs = False
    nominalWidthXError = _NominalWidthUsedError()
    for glyphName in charStrings.keys():
        cs, fdIndex = charStrings.getItemAndSelector(glyphName)
        program = cs.program

        thisLocalSubrs = (
            localSubrs[fdIndex]
            if fdIndex is not None
            else (
                getattr(topDict.Private, "Subrs", [])
                if hasattr(topDict, "Private")
                else []
            )
        )

        # Intentionally use custom type for nominalWidthX, such that any
        # CharString that has an explicit width encoded will throw back to us.
        extractor = T2WidthExtractor(
            thisLocalSubrs,
            globalSubrs,
            nominalWidthXError,
            0,
        )
        try:
            extractor.execute(cs)
        except _NominalWidthUsedError:
            # Program has explicit width. We want to drop it, but can't
            # just pop the first number since it may be a subroutine call.
            # Instead, when seeing that, we embed the subroutine and recurse.
            # If this ever happened, we later prune unused subroutines.
            while len(program) >= 2 and program[1] in ["callsubr", "callgsubr"]:
                removeUnusedSubrs = True
                subrNumber = program.pop(0)
                assert isinstance(subrNumber, int), subrNumber
                op = program.pop(0)
                bias = extractor.localBias if op == "callsubr" else extractor.globalBias
                subrNumber += bias
                subrSet = thisLocalSubrs if op == "callsubr" else globalSubrs
                subrProgram = subrSet[subrNumber].program
                program[:0] = subrProgram
            # Now pop the actual width
            assert len(program) >= 1, program
            program.pop(0)

        if program and program[-1] == "endchar":
            program.pop()

    if removeUnusedSubrs:
        cff.remove_unused_subroutines()

    # Upconvert TopDict

    cff.major = 2
    cff2GetGlyphOrder = cff.otFont.getGlyphOrder
    topDictData = TopDictIndex(None, cff2GetGlyphOrder)
    for item in cff.topDictIndex:
        # Iterate over, such that all are decompiled
        topDictData.append(item)
    cff.topDictIndex = topDictData
    topDict = topDictData[0]
    if hasattr(topDict, "Private"):
        privateDict = topDict.Private
    else:
        privateDict = None
    opOrder = buildOrder(topDictOperators2)
    topDict.order = opOrder
    topDict.cff2GetGlyphOrder = cff2GetGlyphOrder

    if not hasattr(topDict, "FDArray"):
        fdArray = topDict.FDArray = FDArrayIndex()
        fdArray.strings = None
        fdArray.GlobalSubrs = topDict.GlobalSubrs
        topDict.GlobalSubrs.fdArray = fdArray
        charStrings = topDict.CharStrings
        if charStrings.charStringsAreIndexed:
            charStrings.charStringsIndex.fdArray = fdArray
        else:
            charStrings.fdArray = fdArray
        fontDict = FontDict()
        fontDict.setCFF2(True)
        fdArray.append(fontDict)
        fontDict.Private = privateDict
        privateOpOrder = buildOrder(privateDictOperators2)
        if privateDict is not None:
            for entry in privateDictOperators:
                key = entry[1]
                if key not in privateOpOrder:
                    if key in privateDict.rawDict:
                        # print "Removing private dict", key
                        del privateDict.rawDict[key]
                    if hasattr(privateDict, key):
                        delattr(privateDict, key)
                        # print "Removing privateDict attr", key
    else:
        # clean up the PrivateDicts in the fdArray
        fdArray = topDict.FDArray
        privateOpOrder = buildOrder(privateDictOperators2)
        for fontDict in fdArray:
            fontDict.setCFF2(True)
            for key in list(fontDict.rawDict.keys()):
                if key not in fontDict.order:
                    del fontDict.rawDict[key]
                    if hasattr(fontDict, key):
                        delattr(fontDict, key)

            privateDict = fontDict.Private
            for entry in privateDictOperators:
                key = entry[1]
                if key not in privateOpOrder:
                    if key in list(privateDict.rawDict.keys()):
                        # print "Removing private dict", key
                        del privateDict.rawDict[key]
                    if hasattr(privateDict, key):
                        delattr(privateDict, key)
                        # print "Removing privateDict attr", key

    # Now delete up the deprecated topDict operators from CFF 1.0
    for entry in topDictOperators:
        key = entry[1]
        # We seem to need to keep the charset operator for now,
        # or we fail to compile with some fonts, like AdditionFont.otf.
        # I don't know which kind of CFF font those are. But keeping
        # charset seems to work. It will be removed when we save and
        # read the font again.
        #
        # AdditionFont.otf has <Encoding name="StandardEncoding"/>.
        if key == "charset":
            continue
        if key not in opOrder:
            if key in topDict.rawDict:
                del topDict.rawDict[key]
            if hasattr(topDict, key):
                delattr(topDict, key)

    # TODO(behdad): What does the following comment even mean? Both CFF and CFF2
    # use the same T2Charstring class. I *think* what it means is that the CharStrings
    # were loaded for CFF1, and we need to reload them for CFF2 to set varstore, etc
    # on them. At least that's what I understand. It's probably safe to remove this
    # and just set vstore where needed.
    #
    # See comment above about charset as well.

    # At this point, the Subrs and Charstrings are all still T2Charstring class
    # easiest to fix this by compiling, then decompiling again
    file = BytesIO()
    cff.compile(file, otFont, isCFF2=True)
    file.seek(0)
    cff.decompile(file, otFont, isCFF2=True)


def convertCFFToCFF2(font):
    cff = font["CFF "].cff
    del font["CFF "]
    _convertCFFToCFF2(cff, font)
    table = font["CFF2"] = newTable("CFF2")
    table.cff = cff


def main(args=None):
    """Convert CFF OTF font to CFF2 OTF font"""
    if args is None:
        import sys

        args = sys.argv[1:]

    import argparse

    parser = argparse.ArgumentParser(
        "fonttools cffLib.CFFToCFF2",
        description="Upgrade a CFF font to CFF2.",
    )
    parser.add_argument(
        "input", metavar="INPUT.ttf", help="Input OTF file with CFF table."
    )
    parser.add_argument(
        "-o",
        "--output",
        metavar="OUTPUT.ttf",
        default=None,
        help="Output instance OTF file (default: INPUT-CFF2.ttf).",
    )
    parser.add_argument(
        "--no-recalc-timestamp",
        dest="recalc_timestamp",
        action="store_false",
        help="Don't set the output font's timestamp to the current time.",
    )
    loggingGroup = parser.add_mutually_exclusive_group(required=False)
    loggingGroup.add_argument(
        "-v", "--verbose", action="store_true", help="Run more verbosely."
    )
    loggingGroup.add_argument(
        "-q", "--quiet", action="store_true", help="Turn verbosity off."
    )
    options = parser.parse_args(args)

    from fontTools import configLogger

    configLogger(
        level=("DEBUG" if options.verbose else "ERROR" if options.quiet else "INFO")
    )

    import os

    infile = options.input
    if not os.path.isfile(infile):
        parser.error("No such file '{}'".format(infile))

    outfile = (
        makeOutputFileName(infile, overWrite=True, suffix="-CFF2")
        if not options.output
        else options.output
    )

    font = TTFont(infile, recalcTimestamp=options.recalc_timestamp, recalcBBoxes=False)

    convertCFFToCFF2(font)

    log.info(
        "Saving %s",
        outfile,
    )
    font.save(outfile)


if __name__ == "__main__":
    import sys

    sys.exit(main(sys.argv[1:]))
</file>

<file path="README_ENHANCED.md">
# cffLib

<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "SoftwareSourceCode",
  "name": "cffLib",
  "description": "Directory containing 6 code files with 55 classes and 71 functions",
  "programmingLanguage": [
    {
      "@type": "ComputerLanguage",
      "name": "Python"
    }
  ],
  "featureList": [
    "55 class definitions",
    "71 function definitions"
  ]
}
</script>

## Overview

This directory contains 6 code file(s) with extracted schemas.

## Files and Schemas

### `CFF2ToCFF.py` (python)

**Functions:**
- `_convertCFF2ToCFF(cff, otFont)` - Line 27
- `convertCFF2ToCFF(font)` - Line 147
- `main(args)` - Line 163

**Key Imports:** `argparse`, `collections`, `fontTools`, `fontTools.cffLib`, `fontTools.misc.cliTools` (+8 more)

### `CFFToCFF2.py` (python)

**Classes:**
- `_NominalWidthUsedError` (extends: Exception) - Line 25
  - Methods: __add__, __radd__

**Functions:**
- `_convertCFFToCFF2(cff, otFont)` - Line 33
- `convertCFFToCFF2(font)` - Line 227
- `main(args)` - Line 235

**Key Imports:** `argparse`, `fontTools`, `fontTools.cffLib`, `fontTools.misc.cliTools`, `fontTools.misc.psCharStrings` (+5 more)

### `__init__.py` (python)

**Classes:**
- `CFFFontSet` (extends: object) - Line 48
  - A CFF font "file" can contain more than one font, although this is
  - Methods: decompile, __len__, keys, values, __getitem__ (+8 more)
- `CFFWriter` (extends: object) - Line 327
  - Helper class for serializing CFF data to binary. Used by
  - Methods: __init__, add, toFile
- `IndexCompiler` (extends: object) - Line 389
  - Base class for writing CFF `INDEX data <https://docs.microsoft.com/en-us/typography/opentype/spec/cff2#5-index-data>`_
  - Methods: __init__, getItems, getOffsets, getDataLength, toFile
- `IndexedStringsCompiler` (extends: IndexCompiler) - Line 465
  - Methods: getItems
- `TopDictIndexCompiler` (extends: IndexCompiler) - Line 470
  - Helper class for writing the TopDict to binary.
  - Methods: getItems, getChildren, getOffsets, getDataLength, toFile
- `FDArrayIndexCompiler` (extends: IndexCompiler) - Line 506
  - Helper class for writing the
  - Methods: getItems, getChildren, toFile, setPos
- `GlobalSubrsCompiler` (extends: IndexCompiler) - Line 547
  - Helper class for writing the `global subroutine INDEX <https://docs.microsoft.com/en-us/typography/opentype/spec/cff2#9-local-and-global-subr-indexes>`_
  - Methods: getItems
- `SubrsCompiler` (extends: GlobalSubrsCompiler) - Line 559
  - Helper class for writing the `local subroutine INDEX <https://docs.microsoft.com/en-us/typography/opentype/spec/cff2#9-local-and-global-subr-indexes>`_
  - Methods: setPos
- `CharStringsCompiler` (extends: GlobalSubrsCompiler) - Line 568
  - Helper class for writing the `CharStrings INDEX <https://docs.microsoft.com/en-us/typography/opentype/spec/cff2#9-local-and-global-subr-indexes>`_
  - Methods: getItems, setPos
- `Index` (extends: object) - Line 583
  - This class represents what the CFF spec calls an INDEX (an array of
  - Methods: __init__, __len__, __getitem__, __setitem__, produceItem (+3 more)
- `GlobalSubrsIndex` (extends: Index) - Line 654
  - This index contains all the global subroutines in the font. A global
  - Methods: __init__, produceItem, toXML, fromXML, getItemAndSelector
- `SubrsIndex` (extends: GlobalSubrsIndex) - Line 761
  - This index contains a glyph's local subroutines. A local subroutine is a
- `TopDictIndex` (extends: Index) - Line 769
  - This index represents the array of ``TopDict`` structures in the font
  - Methods: __init__, produceItem, toXML
- `FDArrayIndex` (extends: Index) - Line 824
  - Methods: toXML, produceItem, fromXML
- `VarStoreData` (extends: object) - Line 859
  - Methods: __init__, decompile, compile, writeXML, xmlRead (+2 more)
- `FDSelect` (extends: object) - Line 913
  - Methods: __init__, __len__, __getitem__, __setitem__, append
- `CharStrings` (extends: object) - Line 977
  - The ``CharStrings`` in the font represent the instructions for drawing
  - Methods: __init__, keys, values, has_key, __len__ (+5 more)
- `SimpleConverter` (extends: object) - Line 1194
  - Methods: read, _read, write, xmlWrite, xmlRead
- `ASCIIConverter` (extends: SimpleConverter) - Line 1219
  - Methods: _read, write, xmlWrite, xmlRead
- `Latin1Converter` (extends: SimpleConverter) - Line 1234
  - Methods: _read, write, xmlWrite, xmlRead
- `NumberConverter` (extends: SimpleConverter) - Line 1274
  - Methods: xmlWrite, xmlRead
- `ArrayConverter` (extends: SimpleConverter) - Line 1299
  - Methods: xmlWrite, xmlRead
- `TableConverter` (extends: SimpleConverter) - Line 1327
  - Methods: xmlWrite, xmlRead
- `PrivateDictConverter` (extends: TableConverter) - Line 1345
  - Methods: getClass, _read, write
- `SubrsConverter` (extends: TableConverter) - Line 1368
  - Methods: getClass, _read, write
- `CharStringsConverter` (extends: TableConverter) - Line 1382
  - Methods: _read, write, xmlRead
- `CharsetConverter` (extends: SimpleConverter) - Line 1443
  - Methods: _read, write, xmlWrite, xmlRead
- `CharsetCompiler` (extends: object) - Line 1505
  - Methods: __init__, setPos, getDataLength, toFile
- `EncodingCompiler` (extends: object) - Line 1640
  - Methods: __init__, setPos, getDataLength, toFile
- `EncodingConverter` (extends: SimpleConverter) - Line 1661
  - Methods: _read, write, xmlWrite, xmlRead
- `FDArrayConverter` (extends: TableConverter) - Line 1838
  - Methods: _read, write, xmlRead
- `FDSelectConverter` (extends: SimpleConverter) - Line 1866
  - Methods: _read, write, xmlWrite, xmlRead
- `VarStoreConverter` (extends: SimpleConverter) - Line 1890
  - Methods: _read, write, xmlWrite, xmlRead
- `FDSelectCompiler` (extends: object) - Line 1960
  - Methods: __init__, setPos, getDataLength, toFile
- `VarStoreCompiler` (extends: object) - Line 1993
  - Methods: __init__, setPos, getDataLength, toFile
- `ROSConverter` (extends: SimpleConverter) - Line 2012
  - Methods: xmlWrite, xmlRead
- `TopDictDecompiler` (extends: psCharStrings.DictDecompiler) - Line 2166
- `PrivateDictDecompiler` (extends: psCharStrings.DictDecompiler) - Line 2170
- `DictCompiler` (extends: object) - Line 2174
  - Methods: __init__, setPos, getDataLength, compile, toFile (+5 more)
- `TopDictCompiler` (extends: DictCompiler) - Line 2347
  - Methods: getChildren
- `FontDictCompiler` (extends: DictCompiler) - Line 2408
  - Methods: __init__, getChildren
- `PrivateDictCompiler` (extends: DictCompiler) - Line 2453
  - Methods: setPos, getChildren
- `BaseDict` (extends: object) - Line 2469
  - Methods: __init__, decompile, postDecompile, getCompiler, __getattr__ (+2 more)
- `TopDict` (extends: BaseDict) - Line 2544
  - The ``TopDict`` represents the top-level dictionary holding font
  - Methods: __init__, getGlyphOrder, postDecompile, toXML, decompileAllCharStrings (+1 more)
- `FontDict` (extends: BaseDict) - Line 2652
  - Methods: __init__, setCFF2
- `PrivateDict` (extends: BaseDict) - Line 2710
  - Methods: __init__, in_cff2, getNumRegions
- `IndexedStrings` (extends: object) - Line 2747
  - SID -> string mapping.
  - Methods: __init__, getCompiler, __len__, __getitem__, getSID (+2 more)

**Functions:**
- `calcOffSize(largestOffset)` - Line 377
- `readCard8(file)` - Line 1116
- `readCard16(file)` - Line 1120
- `readCard32(file)` - Line 1125
- `writeCard8(file, value)` - Line 1130
- `writeCard16(file, value)` - Line 1134
- `writeCard32(file, value)` - Line 1138
- `packCard8(value)` - Line 1142
- `packCard16(value)` - Line 1146
- `packCard32(value)` - Line 1150
- ... and 25 more functions

**Key Imports:** `CFF2ToCFF`, `CFFToCFF2`, `array`, `fontTools.misc`, `fontTools.misc.arrayTools` (+9 more)

### `specializer.py` (python)

**Classes:**
- `_GeneralizerDecombinerCommandsMap` (extends: object) - Line 164
  - Methods: rmoveto, hmoveto, vmoveto, rlineto, hlineto (+8 more)

**Functions:**
- `stringToProgram(string)` - Line 19
- `programToString(program)` - Line 35
- `programToCommands(program, getNumRegions)` - Line 39
- `_flattenBlendArgs(args)` - Line 131
- `commandsToProgram(commands)` - Line 142
- `_everyN(el, n)` - Line 155
- `_convertBlendOpToArgs(blendList)` - Line 314
- `generalizeCommands(commands, ignoreErrors)` - Line 356
- `generalizeProgram(program, getNumRegions)` - Line 397
- `_categorizeVector(v)` - Line 403
- ... and 7 more functions

**Key Imports:** `argparse`, `doctest`, `fontTools.cffLib`, `fontTools.misc.cliTools`, `fontTools.ttLib` (+1 more)

### `transforms.py` (python)

**Classes:**
- `StopHintCountEvent` (extends: Exception) - Line 12
- `_DesubroutinizingT2Decompiler` (extends: SimpleT2Decompiler) - Line 16
  - Methods: __init__, execute, op_callsubr, op_callgsubr, stop_hint_count (+2 more)
- `_MarkingT2Decompiler` (extends: SimpleT2Decompiler) - Line 131
  - Methods: __init__, op_callsubr, op_callgsubr
- `_DehintingT2Decompiler` (extends: T2WidthExtractor) - Line 147
  - Methods: __init__, execute, op_callsubr, op_callgsubr, op_hstem (+8 more)
- `Hints` (extends: object) - Line 148
  - Methods: __init__

**Functions:**
- `_uniq_sort(l)` - Line 8
- `desubroutinizeCharString(cs)` - Line 97
- `desubroutinize(cff)` - Line 107
- `_cs_subset_subroutines(charstring, subrs, gsubrs)` - Line 297
- `_cs_drop_hints(charstring)` - Line 310
- `remove_hints(cff)` - Line 350
- `_pd_delete_empty_subrs(private_dict)` - Line 416
- `remove_unused_subroutines(cff)` - Line 423

**Key Imports:** `fontTools.misc.psCharStrings`

### `width.py` (python)

**Classes:**
- `missingdict` (extends: dict) - Line 19
  - Methods: __init__, __missing__

**Functions:**
- `cumSum(f, op, start, decreasing)` - Line 27
- `byteCost(widths, default, nominal)` - Line 50
- `optimizeWidthsBruteforce(widths)` - Line 71
- `optimizeWidths(widths)` - Line 100
- `main(args)` - Line 167

**Key Imports:** `argparse`, `collections`, `doctest`, `fontTools.ttLib`, `functools` (+2 more)

---
*Generated by Enhanced Schema Generator with schema.org markup*
</file>

<file path="README.md">
# cffLib

## Overview

This directory contains 6 code file(s) with extracted schemas.

## Files and Schemas

### `CFF2ToCFF.py` (python)

**Functions:**
- `_convertCFF2ToCFF(cff, otFont)` - Line 27
- `convertCFF2ToCFF(font)` - Line 147
- `main(args)` - Line 163

**Key Imports:** `argparse`, `collections`, `fontTools`, `fontTools.cffLib`, `fontTools.misc.cliTools` (+8 more)

### `CFFToCFF2.py` (python)

**Classes:**
- `_NominalWidthUsedError` (extends: Exception) - Line 25
  - Methods: __add__, __radd__

**Functions:**
- `_convertCFFToCFF2(cff, otFont)` - Line 33
- `convertCFFToCFF2(font)` - Line 227
- `main(args)` - Line 235

**Key Imports:** `argparse`, `fontTools`, `fontTools.cffLib`, `fontTools.misc.cliTools`, `fontTools.misc.psCharStrings` (+5 more)

### `__init__.py` (python)

**Classes:**
- `CFFFontSet` (extends: object) - Line 48
  - A CFF font "file" can contain more than one font, although this is
  - Methods: decompile, __len__, keys, values, __getitem__ (+8 more)
- `CFFWriter` (extends: object) - Line 327
  - Helper class for serializing CFF data to binary. Used by
  - Methods: __init__, add, toFile
- `IndexCompiler` (extends: object) - Line 389
  - Base class for writing CFF `INDEX data <https://docs.microsoft.com/en-us/typography/opentype/spec/cff2#5-index-data>`_
  - Methods: __init__, getItems, getOffsets, getDataLength, toFile
- `IndexedStringsCompiler` (extends: IndexCompiler) - Line 465
  - Methods: getItems
- `TopDictIndexCompiler` (extends: IndexCompiler) - Line 470
  - Helper class for writing the TopDict to binary.
  - Methods: getItems, getChildren, getOffsets, getDataLength, toFile
- `FDArrayIndexCompiler` (extends: IndexCompiler) - Line 506
  - Helper class for writing the
  - Methods: getItems, getChildren, toFile, setPos
- `GlobalSubrsCompiler` (extends: IndexCompiler) - Line 547
  - Helper class for writing the `global subroutine INDEX <https://docs.microsoft.com/en-us/typography/opentype/spec/cff2#9-local-and-global-subr-indexes>`_
  - Methods: getItems
- `SubrsCompiler` (extends: GlobalSubrsCompiler) - Line 559
  - Helper class for writing the `local subroutine INDEX <https://docs.microsoft.com/en-us/typography/opentype/spec/cff2#9-local-and-global-subr-indexes>`_
  - Methods: setPos
- `CharStringsCompiler` (extends: GlobalSubrsCompiler) - Line 568
  - Helper class for writing the `CharStrings INDEX <https://docs.microsoft.com/en-us/typography/opentype/spec/cff2#9-local-and-global-subr-indexes>`_
  - Methods: getItems, setPos
- `Index` (extends: object) - Line 583
  - This class represents what the CFF spec calls an INDEX (an array of
  - Methods: __init__, __len__, __getitem__, __setitem__, produceItem (+3 more)
- `GlobalSubrsIndex` (extends: Index) - Line 654
  - This index contains all the global subroutines in the font. A global
  - Methods: __init__, produceItem, toXML, fromXML, getItemAndSelector
- `SubrsIndex` (extends: GlobalSubrsIndex) - Line 761
  - This index contains a glyph's local subroutines. A local subroutine is a
- `TopDictIndex` (extends: Index) - Line 769
  - This index represents the array of ``TopDict`` structures in the font
  - Methods: __init__, produceItem, toXML
- `FDArrayIndex` (extends: Index) - Line 824
  - Methods: toXML, produceItem, fromXML
- `VarStoreData` (extends: object) - Line 859
  - Methods: __init__, decompile, compile, writeXML, xmlRead (+2 more)
- `FDSelect` (extends: object) - Line 913
  - Methods: __init__, __len__, __getitem__, __setitem__, append
- `CharStrings` (extends: object) - Line 977
  - The ``CharStrings`` in the font represent the instructions for drawing
  - Methods: __init__, keys, values, has_key, __len__ (+5 more)
- `SimpleConverter` (extends: object) - Line 1194
  - Methods: read, _read, write, xmlWrite, xmlRead
- `ASCIIConverter` (extends: SimpleConverter) - Line 1219
  - Methods: _read, write, xmlWrite, xmlRead
- `Latin1Converter` (extends: SimpleConverter) - Line 1234
  - Methods: _read, write, xmlWrite, xmlRead
- `NumberConverter` (extends: SimpleConverter) - Line 1274
  - Methods: xmlWrite, xmlRead
- `ArrayConverter` (extends: SimpleConverter) - Line 1299
  - Methods: xmlWrite, xmlRead
- `TableConverter` (extends: SimpleConverter) - Line 1327
  - Methods: xmlWrite, xmlRead
- `PrivateDictConverter` (extends: TableConverter) - Line 1345
  - Methods: getClass, _read, write
- `SubrsConverter` (extends: TableConverter) - Line 1368
  - Methods: getClass, _read, write
- `CharStringsConverter` (extends: TableConverter) - Line 1382
  - Methods: _read, write, xmlRead
- `CharsetConverter` (extends: SimpleConverter) - Line 1443
  - Methods: _read, write, xmlWrite, xmlRead
- `CharsetCompiler` (extends: object) - Line 1505
  - Methods: __init__, setPos, getDataLength, toFile
- `EncodingCompiler` (extends: object) - Line 1640
  - Methods: __init__, setPos, getDataLength, toFile
- `EncodingConverter` (extends: SimpleConverter) - Line 1661
  - Methods: _read, write, xmlWrite, xmlRead
- `FDArrayConverter` (extends: TableConverter) - Line 1838
  - Methods: _read, write, xmlRead
- `FDSelectConverter` (extends: SimpleConverter) - Line 1866
  - Methods: _read, write, xmlWrite, xmlRead
- `VarStoreConverter` (extends: SimpleConverter) - Line 1890
  - Methods: _read, write, xmlWrite, xmlRead
- `FDSelectCompiler` (extends: object) - Line 1960
  - Methods: __init__, setPos, getDataLength, toFile
- `VarStoreCompiler` (extends: object) - Line 1993
  - Methods: __init__, setPos, getDataLength, toFile
- `ROSConverter` (extends: SimpleConverter) - Line 2012
  - Methods: xmlWrite, xmlRead
- `TopDictDecompiler` (extends: psCharStrings.DictDecompiler) - Line 2166
- `PrivateDictDecompiler` (extends: psCharStrings.DictDecompiler) - Line 2170
- `DictCompiler` (extends: object) - Line 2174
  - Methods: __init__, setPos, getDataLength, compile, toFile (+5 more)
- `TopDictCompiler` (extends: DictCompiler) - Line 2347
  - Methods: getChildren
- `FontDictCompiler` (extends: DictCompiler) - Line 2408
  - Methods: __init__, getChildren
- `PrivateDictCompiler` (extends: DictCompiler) - Line 2453
  - Methods: setPos, getChildren
- `BaseDict` (extends: object) - Line 2469
  - Methods: __init__, decompile, postDecompile, getCompiler, __getattr__ (+2 more)
- `TopDict` (extends: BaseDict) - Line 2544
  - The ``TopDict`` represents the top-level dictionary holding font
  - Methods: __init__, getGlyphOrder, postDecompile, toXML, decompileAllCharStrings (+1 more)
- `FontDict` (extends: BaseDict) - Line 2652
  - Methods: __init__, setCFF2
- `PrivateDict` (extends: BaseDict) - Line 2710
  - Methods: __init__, in_cff2, getNumRegions
- `IndexedStrings` (extends: object) - Line 2747
  - SID -> string mapping.
  - Methods: __init__, getCompiler, __len__, __getitem__, getSID (+2 more)

**Functions:**
- `calcOffSize(largestOffset)` - Line 377
- `readCard8(file)` - Line 1116
- `readCard16(file)` - Line 1120
- `readCard32(file)` - Line 1125
- `writeCard8(file, value)` - Line 1130
- `writeCard16(file, value)` - Line 1134
- `writeCard32(file, value)` - Line 1138
- `packCard8(value)` - Line 1142
- `packCard16(value)` - Line 1146
- `packCard32(value)` - Line 1150
- ... and 25 more functions

**Key Imports:** `CFF2ToCFF`, `CFFToCFF2`, `array`, `fontTools.misc`, `fontTools.misc.arrayTools` (+9 more)

### `specializer.py` (python)

**Classes:**
- `_GeneralizerDecombinerCommandsMap` (extends: object) - Line 164
  - Methods: rmoveto, hmoveto, vmoveto, rlineto, hlineto (+8 more)

**Functions:**
- `stringToProgram(string)` - Line 19
- `programToString(program)` - Line 35
- `programToCommands(program, getNumRegions)` - Line 39
- `_flattenBlendArgs(args)` - Line 131
- `commandsToProgram(commands)` - Line 142
- `_everyN(el, n)` - Line 155
- `_convertBlendOpToArgs(blendList)` - Line 314
- `generalizeCommands(commands, ignoreErrors)` - Line 356
- `generalizeProgram(program, getNumRegions)` - Line 397
- `_categorizeVector(v)` - Line 403
- ... and 7 more functions

**Key Imports:** `argparse`, `doctest`, `fontTools.cffLib`, `fontTools.misc.cliTools`, `fontTools.ttLib` (+1 more)

### `transforms.py` (python)

**Classes:**
- `StopHintCountEvent` (extends: Exception) - Line 12
- `_DesubroutinizingT2Decompiler` (extends: SimpleT2Decompiler) - Line 16
  - Methods: __init__, execute, op_callsubr, op_callgsubr, stop_hint_count (+2 more)
- `_MarkingT2Decompiler` (extends: SimpleT2Decompiler) - Line 131
  - Methods: __init__, op_callsubr, op_callgsubr
- `_DehintingT2Decompiler` (extends: T2WidthExtractor) - Line 147
  - Methods: __init__, execute, op_callsubr, op_callgsubr, op_hstem (+8 more)
- `Hints` (extends: object) - Line 148
  - Methods: __init__

**Functions:**
- `_uniq_sort(l)` - Line 8
- `desubroutinizeCharString(cs)` - Line 97
- `desubroutinize(cff)` - Line 107
- `_cs_subset_subroutines(charstring, subrs, gsubrs)` - Line 297
- `_cs_drop_hints(charstring)` - Line 310
- `remove_hints(cff)` - Line 350
- `_pd_delete_empty_subrs(private_dict)` - Line 416
- `remove_unused_subroutines(cff)` - Line 423

**Key Imports:** `fontTools.misc.psCharStrings`

### `width.py` (python)

**Classes:**
- `missingdict` (extends: dict) - Line 19
  - Methods: __init__, __missing__

**Functions:**
- `cumSum(f, op, start, decreasing)` - Line 27
- `byteCost(widths, default, nominal)` - Line 50
- `optimizeWidthsBruteforce(widths)` - Line 71
- `optimizeWidths(widths)` - Line 100
- `main(args)` - Line 167

**Key Imports:** `argparse`, `collections`, `doctest`, `fontTools.ttLib`, `functools` (+2 more)

---
*Generated by Schema Generator*
</file>

<file path="specializer.py">
# -*- coding: utf-8 -*-

"""T2CharString operator specializer and generalizer.

PostScript glyph drawing operations can be expressed in multiple different
ways. For example, as well as the ``lineto`` operator, there is also a
``hlineto`` operator which draws a horizontal line, removing the need to
specify a ``dx`` coordinate, and a ``vlineto`` operator which draws a
vertical line, removing the need to specify a ``dy`` coordinate. As well
as decompiling :class:`fontTools.misc.psCharStrings.T2CharString` objects
into lists of operations, this module allows for conversion between general
and specific forms of the operation.

"""

from fontTools.cffLib import maxStackLimit


def stringToProgram(string):
    if isinstance(string, str):
        string = string.split()
    program = []
    for token in string:
        try:
            token = int(token)
        except ValueError:
            try:
                token = float(token)
            except ValueError:
                pass
        program.append(token)
    return program


def programToString(program):
    return " ".join(str(x) for x in program)


def programToCommands(program, getNumRegions=None):
    """Takes a T2CharString program list and returns list of commands.
    Each command is a two-tuple of commandname,arg-list.  The commandname might
    be empty string if no commandname shall be emitted (used for glyph width,
    hintmask/cntrmask argument, as well as stray arguments at the end of the
    program ().
    'getNumRegions' may be None, or a callable object. It must return the
    number of regions. 'getNumRegions' takes a single argument, vsindex. It
    returns the numRegions for the vsindex.
    The Charstring may or may not start with a width value. If the first
    non-blend operator has an odd number of arguments, then the first argument is
    a width, and is popped off. This is complicated with blend operators, as
    there may be more than one before the first hint or moveto operator, and each
    one reduces several arguments to just one list argument. We have to sum the
    number of arguments that are not part of the blend arguments, and all the
    'numBlends' values. We could instead have said that by definition, if there
    is a blend operator, there is no width value, since CFF2 Charstrings don't
    have width values. I discussed this with Behdad, and we are allowing for an
    initial width value in this case because developers may assemble a CFF2
    charstring from CFF Charstrings, which could have width values.
    """

    seenWidthOp = False
    vsIndex = 0
    lenBlendStack = 0
    lastBlendIndex = 0
    commands = []
    stack = []
    it = iter(program)

    for token in it:
        if not isinstance(token, str):
            stack.append(token)
            continue

        if token == "blend":
            assert getNumRegions is not None
            numSourceFonts = 1 + getNumRegions(vsIndex)
            # replace the blend op args on the stack with a single list
            # containing all the blend op args.
            numBlends = stack[-1]
            numBlendArgs = numBlends * numSourceFonts + 1
            # replace first blend op by a list of the blend ops.
            stack[-numBlendArgs:] = [stack[-numBlendArgs:]]
            lenStack = len(stack)
            lenBlendStack += numBlends + lenStack - 1
            lastBlendIndex = lenStack
            # if a blend op exists, this is or will be a CFF2 charstring.
            continue

        elif token == "vsindex":
            vsIndex = stack[-1]
            assert type(vsIndex) is int

        elif (not seenWidthOp) and token in {
            "hstem",
            "hstemhm",
            "vstem",
            "vstemhm",
            "cntrmask",
            "hintmask",
            "hmoveto",
            "vmoveto",
            "rmoveto",
            "endchar",
        }:
            seenWidthOp = True
            parity = token in {"hmoveto", "vmoveto"}
            if lenBlendStack:
                # lenBlendStack has the number of args represented by the last blend
                # arg and all the preceding args. We need to now add the number of
                # args following the last blend arg.
                numArgs = lenBlendStack + len(stack[lastBlendIndex:])
            else:
                numArgs = len(stack)
            if numArgs and (numArgs % 2) ^ parity:
                width = stack.pop(0)
                commands.append(("", [width]))

        if token in {"hintmask", "cntrmask"}:
            if stack:
                commands.append(("", stack))
            commands.append((token, []))
            commands.append(("", [next(it)]))
        else:
            commands.append((token, stack))
        stack = []
    if stack:
        commands.append(("", stack))
    return commands


def _flattenBlendArgs(args):
    token_list = []
    for arg in args:
        if isinstance(arg, list):
            token_list.extend(arg)
            token_list.append("blend")
        else:
            token_list.append(arg)
    return token_list


def commandsToProgram(commands):
    """Takes a commands list as returned by programToCommands() and converts
    it back to a T2CharString program list."""
    program = []
    for op, args in commands:
        if any(isinstance(arg, list) for arg in args):
            args = _flattenBlendArgs(args)
        program.extend(args)
        if op:
            program.append(op)
    return program


def _everyN(el, n):
    """Group the list el into groups of size n"""
    l = len(el)
    if l % n != 0:
        raise ValueError(el)
    for i in range(0, l, n):
        yield el[i : i + n]


class _GeneralizerDecombinerCommandsMap(object):
    @staticmethod
    def rmoveto(args):
        if len(args) != 2:
            raise ValueError(args)
        yield ("rmoveto", args)

    @staticmethod
    def hmoveto(args):
        if len(args) != 1:
            raise ValueError(args)
        yield ("rmoveto", [args[0], 0])

    @staticmethod
    def vmoveto(args):
        if len(args) != 1:
            raise ValueError(args)
        yield ("rmoveto", [0, args[0]])

    @staticmethod
    def rlineto(args):
        if not args:
            raise ValueError(args)
        for args in _everyN(args, 2):
            yield ("rlineto", args)

    @staticmethod
    def hlineto(args):
        if not args:
            raise ValueError(args)
        it = iter(args)
        try:
            while True:
                yield ("rlineto", [next(it), 0])
                yield ("rlineto", [0, next(it)])
        except StopIteration:
            pass

    @staticmethod
    def vlineto(args):
        if not args:
            raise ValueError(args)
        it = iter(args)
        try:
            while True:
                yield ("rlineto", [0, next(it)])
                yield ("rlineto", [next(it), 0])
        except StopIteration:
            pass

    @staticmethod
    def rrcurveto(args):
        if not args:
            raise ValueError(args)
        for args in _everyN(args, 6):
            yield ("rrcurveto", args)

    @staticmethod
    def hhcurveto(args):
        l = len(args)
        if l < 4 or l % 4 > 1:
            raise ValueError(args)
        if l % 2 == 1:
            yield ("rrcurveto", [args[1], args[0], args[2], args[3], args[4], 0])
            args = args[5:]
        for args in _everyN(args, 4):
            yield ("rrcurveto", [args[0], 0, args[1], args[2], args[3], 0])

    @staticmethod
    def vvcurveto(args):
        l = len(args)
        if l < 4 or l % 4 > 1:
            raise ValueError(args)
        if l % 2 == 1:
            yield ("rrcurveto", [args[0], args[1], args[2], args[3], 0, args[4]])
            args = args[5:]
        for args in _everyN(args, 4):
            yield ("rrcurveto", [0, args[0], args[1], args[2], 0, args[3]])

    @staticmethod
    def hvcurveto(args):
        l = len(args)
        if l < 4 or l % 8 not in {0, 1, 4, 5}:
            raise ValueError(args)
        last_args = None
        if l % 2 == 1:
            lastStraight = l % 8 == 5
            args, last_args = args[:-5], args[-5:]
        it = _everyN(args, 4)
        try:
            while True:
                args = next(it)
                yield ("rrcurveto", [args[0], 0, args[1], args[2], 0, args[3]])
                args = next(it)
                yield ("rrcurveto", [0, args[0], args[1], args[2], args[3], 0])
        except StopIteration:
            pass
        if last_args:
            args = last_args
            if lastStraight:
                yield ("rrcurveto", [args[0], 0, args[1], args[2], args[4], args[3]])
            else:
                yield ("rrcurveto", [0, args[0], args[1], args[2], args[3], args[4]])

    @staticmethod
    def vhcurveto(args):
        l = len(args)
        if l < 4 or l % 8 not in {0, 1, 4, 5}:
            raise ValueError(args)
        last_args = None
        if l % 2 == 1:
            lastStraight = l % 8 == 5
            args, last_args = args[:-5], args[-5:]
        it = _everyN(args, 4)
        try:
            while True:
                args = next(it)
                yield ("rrcurveto", [0, args[0], args[1], args[2], args[3], 0])
                args = next(it)
                yield ("rrcurveto", [args[0], 0, args[1], args[2], 0, args[3]])
        except StopIteration:
            pass
        if last_args:
            args = last_args
            if lastStraight:
                yield ("rrcurveto", [0, args[0], args[1], args[2], args[3], args[4]])
            else:
                yield ("rrcurveto", [args[0], 0, args[1], args[2], args[4], args[3]])

    @staticmethod
    def rcurveline(args):
        l = len(args)
        if l < 8 or l % 6 != 2:
            raise ValueError(args)
        args, last_args = args[:-2], args[-2:]
        for args in _everyN(args, 6):
            yield ("rrcurveto", args)
        yield ("rlineto", last_args)

    @staticmethod
    def rlinecurve(args):
        l = len(args)
        if l < 8 or l % 2 != 0:
            raise ValueError(args)
        args, last_args = args[:-6], args[-6:]
        for args in _everyN(args, 2):
            yield ("rlineto", args)
        yield ("rrcurveto", last_args)


def _convertBlendOpToArgs(blendList):
    # args is list of blend op args. Since we are supporting
    # recursive blend op calls, some of these args may also
    # be a list of blend op args, and need to be converted before
    # we convert the current list.
    if any([isinstance(arg, list) for arg in blendList]):
        args = [
            i
            for e in blendList
            for i in (_convertBlendOpToArgs(e) if isinstance(e, list) else [e])
        ]
    else:
        args = blendList

    # We now know that blendList contains a blend op argument list, even if
    # some of the args are lists that each contain a blend op argument list.
    # 	Convert from:
    # 		[default font arg sequence x0,...,xn] + [delta tuple for x0] + ... + [delta tuple for xn]
    # 	to:
    # 		[ [x0] + [delta tuple for x0],
    #                 ...,
    #          [xn] + [delta tuple for xn] ]
    numBlends = args[-1]
    # Can't use args.pop() when the args are being used in a nested list
    # comprehension. See calling context
    args = args[:-1]

    l = len(args)
    numRegions = l // numBlends - 1
    if not (numBlends * (numRegions + 1) == l):
        raise ValueError(blendList)

    defaultArgs = [[arg] for arg in args[:numBlends]]
    deltaArgs = args[numBlends:]
    numDeltaValues = len(deltaArgs)
    deltaList = [
        deltaArgs[i : i + numRegions] for i in range(0, numDeltaValues, numRegions)
    ]
    blend_args = [a + b + [1] for a, b in zip(defaultArgs, deltaList)]
    return blend_args


def generalizeCommands(commands, ignoreErrors=False):
    result = []
    mapping = _GeneralizerDecombinerCommandsMap
    for op, args in commands:
        # First, generalize any blend args in the arg list.
        if any([isinstance(arg, list) for arg in args]):
            try:
                args = [
                    n
                    for arg in args
                    for n in (
                        _convertBlendOpToArgs(arg) if isinstance(arg, list) else [arg]
                    )
                ]
            except ValueError:
                if ignoreErrors:
                    # Store op as data, such that consumers of commands do not have to
                    # deal with incorrect number of arguments.
                    result.append(("", args))
                    result.append(("", [op]))
                else:
                    raise

        func = getattr(mapping, op, None)
        if func is None:
            result.append((op, args))
            continue
        try:
            for command in func(args):
                result.append(command)
        except ValueError:
            if ignoreErrors:
                # Store op as data, such that consumers of commands do not have to
                # deal with incorrect number of arguments.
                result.append(("", args))
                result.append(("", [op]))
            else:
                raise
    return result


def generalizeProgram(program, getNumRegions=None, **kwargs):
    return commandsToProgram(
        generalizeCommands(programToCommands(program, getNumRegions), **kwargs)
    )


def _categorizeVector(v):
    """
    Takes X,Y vector v and returns one of r, h, v, or 0 depending on which
    of X and/or Y are zero, plus tuple of nonzero ones.  If both are zero,
    it returns a single zero still.

    >>> _categorizeVector((0,0))
    ('0', (0,))
    >>> _categorizeVector((1,0))
    ('h', (1,))
    >>> _categorizeVector((0,2))
    ('v', (2,))
    >>> _categorizeVector((1,2))
    ('r', (1, 2))
    """
    if not v[0]:
        if not v[1]:
            return "0", v[:1]
        else:
            return "v", v[1:]
    else:
        if not v[1]:
            return "h", v[:1]
        else:
            return "r", v


def _mergeCategories(a, b):
    if a == "0":
        return b
    if b == "0":
        return a
    if a == b:
        return a
    return None


def _negateCategory(a):
    if a == "h":
        return "v"
    if a == "v":
        return "h"
    assert a in "0r"
    return a


def _convertToBlendCmds(args):
    # return a list of blend commands, and
    # the remaining non-blended args, if any.
    num_args = len(args)
    stack_use = 0
    new_args = []
    i = 0
    while i < num_args:
        arg = args[i]
        i += 1
        if not isinstance(arg, list):
            new_args.append(arg)
            stack_use += 1
        else:
            prev_stack_use = stack_use
            # The arg is a tuple of blend values.
            # These are each (master 0,delta 1..delta n, 1)
            # Combine as many successive tuples as we can,
            # up to the max stack limit.
            num_sources = len(arg) - 1
            blendlist = [arg]
            stack_use += 1 + num_sources  # 1 for the num_blends arg

            # if we are here, max stack is the CFF2 max stack.
            # I use the CFF2 max stack limit here rather than
            # the 'maxstack' chosen by the client, as the default
            # maxstack may have been used unintentionally. For all
            # the other operators, this just produces a little less
            # optimization, but here it puts a hard (and low) limit
            # on the number of source fonts that can be used.
            #
            # Make sure the stack depth does not exceed (maxstack - 1), so
            # that subroutinizer can insert subroutine calls at any point.
            while (
                (i < num_args)
                and isinstance(args[i], list)
                and stack_use + num_sources < maxStackLimit
            ):
                blendlist.append(args[i])
                i += 1
                stack_use += num_sources
            # blendList now contains as many single blend tuples as can be
            # combined without exceeding the CFF2 stack limit.
            num_blends = len(blendlist)
            # append the 'num_blends' default font values
            blend_args = []
            for arg in blendlist:
                blend_args.append(arg[0])
            for arg in blendlist:
                assert arg[-1] == 1
                blend_args.extend(arg[1:-1])
            blend_args.append(num_blends)
            new_args.append(blend_args)
            stack_use = prev_stack_use + num_blends

    return new_args


def _addArgs(a, b):
    if isinstance(b, list):
        if isinstance(a, list):
            if len(a) != len(b) or a[-1] != b[-1]:
                raise ValueError()
            return [_addArgs(va, vb) for va, vb in zip(a[:-1], b[:-1])] + [a[-1]]
        else:
            a, b = b, a
    if isinstance(a, list):
        assert a[-1] == 1
        return [_addArgs(a[0], b)] + a[1:]
    return a + b


def _argsStackUse(args):
    stackLen = 0
    maxLen = 0
    for arg in args:
        if type(arg) is list:
            # Blended arg
            maxLen = max(maxLen, stackLen + _argsStackUse(arg))
            stackLen += arg[-1]
        else:
            stackLen += 1
    return max(stackLen, maxLen)


def specializeCommands(
    commands,
    ignoreErrors=False,
    generalizeFirst=True,
    preserveTopology=False,
    maxstack=48,
):
    # We perform several rounds of optimizations.  They are carefully ordered and are:
    #
    # 0. Generalize commands.
    #    This ensures that they are in our expected simple form, with each line/curve only
    #    having arguments for one segment, and using the generic form (rlineto/rrcurveto).
    #    If caller is sure the input is in this form, they can turn off generalization to
    #    save time.
    #
    # 1. Combine successive rmoveto operations.
    #
    # 2. Specialize rmoveto/rlineto/rrcurveto operators into horizontal/vertical variants.
    #    We specialize into some, made-up, variants as well, which simplifies following
    #    passes.
    #
    # 3. Merge or delete redundant operations, to the extent requested.
    #    OpenType spec declares point numbers in CFF undefined.  As such, we happily
    #    change topology.  If client relies on point numbers (in GPOS anchors, or for
    #    hinting purposes(what?)) they can turn this off.
    #
    # 4. Peephole optimization to revert back some of the h/v variants back into their
    #    original "relative" operator (rline/rrcurveto) if that saves a byte.
    #
    # 5. Combine adjacent operators when possible, minding not to go over max stack size.
    #
    # 6. Resolve any remaining made-up operators into real operators.
    #
    # I have convinced myself that this produces optimal bytecode (except for, possibly
    # one byte each time maxstack size prohibits combining.)  YMMV, but you'd be wrong. :-)
    # A dynamic-programming approach can do the same but would be significantly slower.
    #
    # 7. For any args which are blend lists, convert them to a blend command.

    # 0. Generalize commands.
    if generalizeFirst:
        commands = generalizeCommands(commands, ignoreErrors=ignoreErrors)
    else:
        commands = list(commands)  # Make copy since we modify in-place later.

    # 1. Combine successive rmoveto operations.
    for i in range(len(commands) - 1, 0, -1):
        if "rmoveto" == commands[i][0] == commands[i - 1][0]:
            v1, v2 = commands[i - 1][1], commands[i][1]
            commands[i - 1] = (
                "rmoveto",
                [_addArgs(v1[0], v2[0]), _addArgs(v1[1], v2[1])],
            )
            del commands[i]

    # 2. Specialize rmoveto/rlineto/rrcurveto operators into horizontal/vertical variants.
    #
    # We, in fact, specialize into more, made-up, variants that special-case when both
    # X and Y components are zero.  This simplifies the following optimization passes.
    # This case is rare, but OCD does not let me skip it.
    #
    # After this round, we will have four variants that use the following mnemonics:
    #
    #  - 'r' for relative,   ie. non-zero X and non-zero Y,
    #  - 'h' for horizontal, ie. zero X and non-zero Y,
    #  - 'v' for vertical,   ie. non-zero X and zero Y,
    #  - '0' for zeros,      ie. zero X and zero Y.
    #
    # The '0' pseudo-operators are not part of the spec, but help simplify the following
    # optimization rounds.  We resolve them at the end.  So, after this, we will have four
    # moveto and four lineto variants:
    #
    #  - 0moveto, 0lineto
    #  - hmoveto, hlineto
    #  - vmoveto, vlineto
    #  - rmoveto, rlineto
    #
    # and sixteen curveto variants.  For example, a '0hcurveto' operator means a curve
    # dx0,dy0,dx1,dy1,dx2,dy2,dx3,dy3 where dx0, dx1, and dy3 are zero but not dx3.
    # An 'rvcurveto' means dx3 is zero but not dx0,dy0,dy3.
    #
    # There are nine different variants of curves without the '0'.  Those nine map exactly
    # to the existing curve variants in the spec: rrcurveto, and the four variants hhcurveto,
    # vvcurveto, hvcurveto, and vhcurveto each cover two cases, one with an odd number of
    # arguments and one without.  Eg. an hhcurveto with an extra argument (odd number of
    # arguments) is in fact an rhcurveto.  The operators in the spec are designed such that
    # all four of rhcurveto, rvcurveto, hrcurveto, and vrcurveto are encodable for one curve.
    #
    # Of the curve types with '0', the 00curveto is equivalent to a lineto variant.  The rest
    # of the curve types with a 0 need to be encoded as a h or v variant.  Ie. a '0' can be
    # thought of a "don't care" and can be used as either an 'h' or a 'v'.  As such, we always
    # encode a number 0 as argument when we use a '0' variant.  Later on, we can just substitute
    # the '0' with either 'h' or 'v' and it works.
    #
    # When we get to curve splines however, things become more complicated...  XXX finish this.
    # There's one more complexity with splines.  If one side of the spline is not horizontal or
    # vertical (or zero), ie. if it's 'r', then it limits which spline types we can encode.
    # Only hhcurveto and vvcurveto operators can encode a spline starting with 'r', and
    # only hvcurveto and vhcurveto operators can encode a spline ending with 'r'.
    # This limits our merge opportunities later.
    #
    for i in range(len(commands)):
        op, args = commands[i]

        if op in {"rmoveto", "rlineto"}:
            c, args = _categorizeVector(args)
            commands[i] = c + op[1:], args
            continue

        if op == "rrcurveto":
            c1, args1 = _categorizeVector(args[:2])
            c2, args2 = _categorizeVector(args[-2:])
            commands[i] = c1 + c2 + "curveto", args1 + args[2:4] + args2
            continue

    # 3. Merge or delete redundant operations, to the extent requested.
    #
    # TODO
    # A 0moveto that comes before all other path operations can be removed.
    # though I find conflicting evidence for this.
    #
    # TODO
    # "If hstem and vstem hints are both declared at the beginning of a
    # CharString, and this sequence is followed directly by the hintmask or
    # cntrmask operators, then the vstem hint operator (or, if applicable,
    # the vstemhm operator) need not be included."
    #
    # "The sequence and form of a CFF2 CharString program may be represented as:
    # {hs* vs* cm* hm* mt subpath}? {mt subpath}*"
    #
    # https://www.microsoft.com/typography/otspec/cff2charstr.htm#section3.1
    #
    # For Type2 CharStrings the sequence is:
    # w? {hs* vs* cm* hm* mt subpath}? {mt subpath}* endchar"

    # Some other redundancies change topology (point numbers).
    if not preserveTopology:
        for i in range(len(commands) - 1, -1, -1):
            op, args = commands[i]

            # A 00curveto is demoted to a (specialized) lineto.
            if op == "00curveto":
                assert len(args) == 4
                c, args = _categorizeVector(args[1:3])
                op = c + "lineto"
                commands[i] = op, args
                # and then...

            # A 0lineto can be deleted.
            if op == "0lineto":
                del commands[i]
                continue

            # Merge adjacent hlineto's and vlineto's.
            # In CFF2 charstrings from variable fonts, each
            # arg item may be a list of blendable values, one from
            # each source font.
            if i and op in {"hlineto", "vlineto"} and (op == commands[i - 1][0]):
                _, other_args = commands[i - 1]
                assert len(args) == 1 and len(other_args) == 1
                try:
                    new_args = [_addArgs(args[0], other_args[0])]
                except ValueError:
                    continue
                commands[i - 1] = (op, new_args)
                del commands[i]
                continue

    # 4. Peephole optimization to revert back some of the h/v variants back into their
    #    original "relative" operator (rline/rrcurveto) if that saves a byte.
    for i in range(1, len(commands) - 1):
        op, args = commands[i]
        prv, nxt = commands[i - 1][0], commands[i + 1][0]

        if op in {"0lineto", "hlineto", "vlineto"} and prv == nxt == "rlineto":
            assert len(args) == 1
            args = [0, args[0]] if op[0] == "v" else [args[0], 0]
            commands[i] = ("rlineto", args)
            continue

        if op[2:] == "curveto" and len(args) == 5 and prv == nxt == "rrcurveto":
            assert (op[0] == "r") ^ (op[1] == "r")
            if op[0] == "v":
                pos = 0
            elif op[0] != "r":
                pos = 1
            elif op[1] == "v":
                pos = 4
            else:
                pos = 5
            # Insert, while maintaining the type of args (can be tuple or list).
            args = args[:pos] + type(args)((0,)) + args[pos:]
            commands[i] = ("rrcurveto", args)
            continue

    # 5. Combine adjacent operators when possible, minding not to go over max stack size.
    stackUse = _argsStackUse(commands[-1][1]) if commands else 0
    for i in range(len(commands) - 1, 0, -1):
        op1, args1 = commands[i - 1]
        op2, args2 = commands[i]
        new_op = None

        # Merge logic...
        if {op1, op2} <= {"rlineto", "rrcurveto"}:
            if op1 == op2:
                new_op = op1
            else:
                l = len(args2)
                if op2 == "rrcurveto" and l == 6:
                    new_op = "rlinecurve"
                elif l == 2:
                    new_op = "rcurveline"

        elif (op1, op2) in {("rlineto", "rlinecurve"), ("rrcurveto", "rcurveline")}:
            new_op = op2

        elif {op1, op2} == {"vlineto", "hlineto"}:
            new_op = op1

        elif "curveto" == op1[2:] == op2[2:]:
            d0, d1 = op1[:2]
            d2, d3 = op2[:2]

            if d1 == "r" or d2 == "r" or d0 == d3 == "r":
                continue

            d = _mergeCategories(d1, d2)
            if d is None:
                continue
            if d0 == "r":
                d = _mergeCategories(d, d3)
                if d is None:
                    continue
                new_op = "r" + d + "curveto"
            elif d3 == "r":
                d0 = _mergeCategories(d0, _negateCategory(d))
                if d0 is None:
                    continue
                new_op = d0 + "r" + "curveto"
            else:
                d0 = _mergeCategories(d0, d3)
                if d0 is None:
                    continue
                new_op = d0 + d + "curveto"

        # Make sure the stack depth does not exceed (maxstack - 1), so
        # that subroutinizer can insert subroutine calls at any point.
        args1StackUse = _argsStackUse(args1)
        combinedStackUse = max(args1StackUse, len(args1) + stackUse)
        if new_op and combinedStackUse < maxstack:
            commands[i - 1] = (new_op, args1 + args2)
            del commands[i]
            stackUse = combinedStackUse
        else:
            stackUse = args1StackUse

    # 6. Resolve any remaining made-up operators into real operators.
    for i in range(len(commands)):
        op, args = commands[i]

        if op in {"0moveto", "0lineto"}:
            commands[i] = "h" + op[1:], args
            continue

        if op[2:] == "curveto" and op[:2] not in {"rr", "hh", "vv", "vh", "hv"}:
            l = len(args)

            op0, op1 = op[:2]
            if (op0 == "r") ^ (op1 == "r"):
                assert l % 2 == 1
            if op0 == "0":
                op0 = "h"
            if op1 == "0":
                op1 = "h"
            if op0 == "r":
                op0 = op1
            if op1 == "r":
                op1 = _negateCategory(op0)
            assert {op0, op1} <= {"h", "v"}, (op0, op1)

            if l % 2:
                if op0 != op1:  # vhcurveto / hvcurveto
                    if (op0 == "h") ^ (l % 8 == 1):
                        # Swap last two args order
                        args = args[:-2] + args[-1:] + args[-2:-1]
                else:  # hhcurveto / vvcurveto
                    if op0 == "h":  # hhcurveto
                        # Swap first two args order
                        args = args[1:2] + args[:1] + args[2:]

            commands[i] = op0 + op1 + "curveto", args
            continue

    # 7. For any series of args which are blend lists, convert the series to a single blend arg.
    for i in range(len(commands)):
        op, args = commands[i]
        if any(isinstance(arg, list) for arg in args):
            commands[i] = op, _convertToBlendCmds(args)

    return commands


def specializeProgram(program, getNumRegions=None, **kwargs):
    return commandsToProgram(
        specializeCommands(programToCommands(program, getNumRegions), **kwargs)
    )


if __name__ == "__main__":
    import sys

    if len(sys.argv) == 1:
        import doctest

        sys.exit(doctest.testmod().failed)

    import argparse

    parser = argparse.ArgumentParser(
        "fonttools cffLib.specializer",
        description="CFF CharString generalizer/specializer",
    )
    parser.add_argument("program", metavar="command", nargs="*", help="Commands.")
    parser.add_argument(
        "--num-regions",
        metavar="NumRegions",
        nargs="*",
        default=None,
        help="Number of variable-font regions for blend opertaions.",
    )
    parser.add_argument(
        "--font",
        metavar="FONTFILE",
        default=None,
        help="CFF2 font to specialize.",
    )
    parser.add_argument(
        "-o",
        "--output-file",
        type=str,
        help="Output font file name.",
    )

    options = parser.parse_args(sys.argv[1:])

    if options.program:
        getNumRegions = (
            None
            if options.num_regions is None
            else lambda vsIndex: int(
                options.num_regions[0 if vsIndex is None else vsIndex]
            )
        )

        program = stringToProgram(options.program)
        print("Program:")
        print(programToString(program))
        commands = programToCommands(program, getNumRegions)
        print("Commands:")
        print(commands)
        program2 = commandsToProgram(commands)
        print("Program from commands:")
        print(programToString(program2))
        assert program == program2
        print("Generalized program:")
        print(programToString(generalizeProgram(program, getNumRegions)))
        print("Specialized program:")
        print(programToString(specializeProgram(program, getNumRegions)))

    if options.font:
        from fontTools.ttLib import TTFont

        font = TTFont(options.font)
        cff2 = font["CFF2"].cff.topDictIndex[0]
        charstrings = cff2.CharStrings
        for glyphName in charstrings.keys():
            charstring = charstrings[glyphName]
            charstring.decompile()
            getNumRegions = charstring.private.getNumRegions
            charstring.program = specializeProgram(
                charstring.program, getNumRegions, maxstack=maxStackLimit
            )

        if options.output_file is None:
            from fontTools.misc.cliTools import makeOutputFileName

            outfile = makeOutputFileName(
                options.font, overWrite=True, suffix=".specialized"
            )
        else:
            outfile = options.output_file
        if outfile:
            print("Saving", outfile)
            font.save(outfile)
</file>

<file path="transforms.py">
from fontTools.misc.psCharStrings import (
    SimpleT2Decompiler,
    T2WidthExtractor,
    calcSubrBias,
)


def _uniq_sort(l):
    return sorted(set(l))


class StopHintCountEvent(Exception):
    pass


class _DesubroutinizingT2Decompiler(SimpleT2Decompiler):
    stop_hintcount_ops = (
        "op_hintmask",
        "op_cntrmask",
        "op_rmoveto",
        "op_hmoveto",
        "op_vmoveto",
    )

    def __init__(self, localSubrs, globalSubrs, private=None):
        SimpleT2Decompiler.__init__(self, localSubrs, globalSubrs, private)

    def execute(self, charString):
        self.need_hintcount = True  # until proven otherwise
        for op_name in self.stop_hintcount_ops:
            setattr(self, op_name, self.stop_hint_count)

        if hasattr(charString, "_desubroutinized"):
            # If a charstring has already been desubroutinized, we will still
            # need to execute it if we need to count hints in order to
            # compute the byte length for mask arguments, and haven't finished
            # counting hints pairs.
            if self.need_hintcount and self.callingStack:
                try:
                    SimpleT2Decompiler.execute(self, charString)
                except StopHintCountEvent:
                    del self.callingStack[-1]
            return

        charString._patches = []
        SimpleT2Decompiler.execute(self, charString)
        desubroutinized = charString.program[:]
        for idx, expansion in reversed(charString._patches):
            assert idx >= 2
            assert desubroutinized[idx - 1] in [
                "callsubr",
                "callgsubr",
            ], desubroutinized[idx - 1]
            assert type(desubroutinized[idx - 2]) == int
            if expansion[-1] == "return":
                expansion = expansion[:-1]
            desubroutinized[idx - 2 : idx] = expansion
        if not self.private.in_cff2:
            if "endchar" in desubroutinized:
                # Cut off after first endchar
                desubroutinized = desubroutinized[
                    : desubroutinized.index("endchar") + 1
                ]

        charString._desubroutinized = desubroutinized
        del charString._patches

    def op_callsubr(self, index):
        subr = self.localSubrs[self.operandStack[-1] + self.localBias]
        SimpleT2Decompiler.op_callsubr(self, index)
        self.processSubr(index, subr)

    def op_callgsubr(self, index):
        subr = self.globalSubrs[self.operandStack[-1] + self.globalBias]
        SimpleT2Decompiler.op_callgsubr(self, index)
        self.processSubr(index, subr)

    def stop_hint_count(self, *args):
        self.need_hintcount = False
        for op_name in self.stop_hintcount_ops:
            setattr(self, op_name, None)
        cs = self.callingStack[-1]
        if hasattr(cs, "_desubroutinized"):
            raise StopHintCountEvent()

    def op_hintmask(self, index):
        SimpleT2Decompiler.op_hintmask(self, index)
        if self.need_hintcount:
            self.stop_hint_count()

    def processSubr(self, index, subr):
        cs = self.callingStack[-1]
        if not hasattr(cs, "_desubroutinized"):
            cs._patches.append((index, subr._desubroutinized))


def desubroutinizeCharString(cs):
    """Desubroutinize a charstring in-place."""
    cs.decompile()
    subrs = getattr(cs.private, "Subrs", [])
    decompiler = _DesubroutinizingT2Decompiler(subrs, cs.globalSubrs, cs.private)
    decompiler.execute(cs)
    cs.program = cs._desubroutinized
    del cs._desubroutinized


def desubroutinize(cff):
    for fontName in cff.fontNames:
        font = cff[fontName]
        cs = font.CharStrings
        for c in cs.values():
            desubroutinizeCharString(c)
        # Delete all the local subrs
        if hasattr(font, "FDArray"):
            for fd in font.FDArray:
                pd = fd.Private
                if hasattr(pd, "Subrs"):
                    del pd.Subrs
                if "Subrs" in pd.rawDict:
                    del pd.rawDict["Subrs"]
        else:
            pd = font.Private
            if hasattr(pd, "Subrs"):
                del pd.Subrs
            if "Subrs" in pd.rawDict:
                del pd.rawDict["Subrs"]
    # as well as the global subrs
    cff.GlobalSubrs.clear()


class _MarkingT2Decompiler(SimpleT2Decompiler):
    def __init__(self, localSubrs, globalSubrs, private):
        SimpleT2Decompiler.__init__(self, localSubrs, globalSubrs, private)
        for subrs in [localSubrs, globalSubrs]:
            if subrs and not hasattr(subrs, "_used"):
                subrs._used = set()

    def op_callsubr(self, index):
        self.localSubrs._used.add(self.operandStack[-1] + self.localBias)
        SimpleT2Decompiler.op_callsubr(self, index)

    def op_callgsubr(self, index):
        self.globalSubrs._used.add(self.operandStack[-1] + self.globalBias)
        SimpleT2Decompiler.op_callgsubr(self, index)


class _DehintingT2Decompiler(T2WidthExtractor):
    class Hints(object):
        def __init__(self):
            # Whether calling this charstring produces any hint stems
            # Note that if a charstring starts with hintmask, it will
            # have has_hint set to True, because it *might* produce an
            # implicit vstem if called under certain conditions.
            self.has_hint = False
            # Index to start at to drop all hints
            self.last_hint = 0
            # Index up to which we know more hints are possible.
            # Only relevant if status is 0 or 1.
            self.last_checked = 0
            # The status means:
            # 0: after dropping hints, this charstring is empty
            # 1: after dropping hints, there may be more hints
            # 	continuing after this, or there might be
            # 	other things.  Not clear yet.
            # 2: no more hints possible after this charstring
            self.status = 0
            # Has hintmask instructions; not recursive
            self.has_hintmask = False
            # List of indices of calls to empty subroutines to remove.
            self.deletions = []

        pass

    def __init__(
        self, css, localSubrs, globalSubrs, nominalWidthX, defaultWidthX, private=None
    ):
        self._css = css
        T2WidthExtractor.__init__(
            self, localSubrs, globalSubrs, nominalWidthX, defaultWidthX
        )
        self.private = private

    def execute(self, charString):
        old_hints = charString._hints if hasattr(charString, "_hints") else None
        charString._hints = self.Hints()

        T2WidthExtractor.execute(self, charString)

        hints = charString._hints

        if hints.has_hint or hints.has_hintmask:
            self._css.add(charString)

        if hints.status != 2:
            # Check from last_check, make sure we didn't have any operators.
            for i in range(hints.last_checked, len(charString.program) - 1):
                if isinstance(charString.program[i], str):
                    hints.status = 2
                    break
                else:
                    hints.status = 1  # There's *something* here
            hints.last_checked = len(charString.program)

        if old_hints:
            assert hints.__dict__ == old_hints.__dict__

    def op_callsubr(self, index):
        subr = self.localSubrs[self.operandStack[-1] + self.localBias]
        T2WidthExtractor.op_callsubr(self, index)
        self.processSubr(index, subr)

    def op_callgsubr(self, index):
        subr = self.globalSubrs[self.operandStack[-1] + self.globalBias]
        T2WidthExtractor.op_callgsubr(self, index)
        self.processSubr(index, subr)

    def op_hstem(self, index):
        T2WidthExtractor.op_hstem(self, index)
        self.processHint(index)

    def op_vstem(self, index):
        T2WidthExtractor.op_vstem(self, index)
        self.processHint(index)

    def op_hstemhm(self, index):
        T2WidthExtractor.op_hstemhm(self, index)
        self.processHint(index)

    def op_vstemhm(self, index):
        T2WidthExtractor.op_vstemhm(self, index)
        self.processHint(index)

    def op_hintmask(self, index):
        rv = T2WidthExtractor.op_hintmask(self, index)
        self.processHintmask(index)
        return rv

    def op_cntrmask(self, index):
        rv = T2WidthExtractor.op_cntrmask(self, index)
        self.processHintmask(index)
        return rv

    def processHintmask(self, index):
        cs = self.callingStack[-1]
        hints = cs._hints
        hints.has_hintmask = True
        if hints.status != 2:
            # Check from last_check, see if we may be an implicit vstem
            for i in range(hints.last_checked, index - 1):
                if isinstance(cs.program[i], str):
                    hints.status = 2
                    break
            else:
                # We are an implicit vstem
                hints.has_hint = True
                hints.last_hint = index + 1
                hints.status = 0
        hints.last_checked = index + 1

    def processHint(self, index):
        cs = self.callingStack[-1]
        hints = cs._hints
        hints.has_hint = True
        hints.last_hint = index
        hints.last_checked = index

    def processSubr(self, index, subr):
        cs = self.callingStack[-1]
        hints = cs._hints
        subr_hints = subr._hints

        # Check from last_check, make sure we didn't have
        # any operators.
        if hints.status != 2:
            for i in range(hints.last_checked, index - 1):
                if isinstance(cs.program[i], str):
                    hints.status = 2
                    break
            hints.last_checked = index

        if hints.status != 2:
            if subr_hints.has_hint:
                hints.has_hint = True

                # Decide where to chop off from
                if subr_hints.status == 0:
                    hints.last_hint = index
                else:
                    hints.last_hint = index - 2  # Leave the subr call in

        elif subr_hints.status == 0:
            hints.deletions.append(index)

        hints.status = max(hints.status, subr_hints.status)


def _cs_subset_subroutines(charstring, subrs, gsubrs):
    p = charstring.program
    for i in range(1, len(p)):
        if p[i] == "callsubr":
            assert isinstance(p[i - 1], int)
            p[i - 1] = subrs._used.index(p[i - 1] + subrs._old_bias) - subrs._new_bias
        elif p[i] == "callgsubr":
            assert isinstance(p[i - 1], int)
            p[i - 1] = (
                gsubrs._used.index(p[i - 1] + gsubrs._old_bias) - gsubrs._new_bias
            )


def _cs_drop_hints(charstring):
    hints = charstring._hints

    if hints.deletions:
        p = charstring.program
        for idx in reversed(hints.deletions):
            del p[idx - 2 : idx]

    if hints.has_hint:
        assert not hints.deletions or hints.last_hint <= hints.deletions[0]
        charstring.program = charstring.program[hints.last_hint :]
        if not charstring.program:
            # TODO CFF2 no need for endchar.
            charstring.program.append("endchar")
        if hasattr(charstring, "width"):
            # Insert width back if needed
            if charstring.width != charstring.private.defaultWidthX:
                # For CFF2 charstrings, this should never happen
                assert (
                    charstring.private.defaultWidthX is not None
                ), "CFF2 CharStrings must not have an initial width value"
                charstring.program.insert(
                    0, charstring.width - charstring.private.nominalWidthX
                )

    if hints.has_hintmask:
        i = 0
        p = charstring.program
        while i < len(p):
            if p[i] in ["hintmask", "cntrmask"]:
                assert i + 1 <= len(p)
                del p[i : i + 2]
                continue
            i += 1

    assert len(charstring.program)

    del charstring._hints


def remove_hints(cff, *, removeUnusedSubrs: bool = True):
    for fontname in cff.keys():
        font = cff[fontname]
        cs = font.CharStrings
        # This can be tricky, but doesn't have to. What we do is:
        #
        # - Run all used glyph charstrings and recurse into subroutines,
        # - For each charstring (including subroutines), if it has any
        #   of the hint stem operators, we mark it as such.
        #   Upon returning, for each charstring we note all the
        #   subroutine calls it makes that (recursively) contain a stem,
        # - Dropping hinting then consists of the following two ops:
        #   * Drop the piece of the program in each charstring before the
        #     last call to a stem op or a stem-calling subroutine,
        #   * Drop all hintmask operations.
        # - It's trickier... A hintmask right after hints and a few numbers
        #    will act as an implicit vstemhm. As such, we track whether
        #    we have seen any non-hint operators so far and do the right
        #    thing, recursively... Good luck understanding that :(
        css = set()
        for c in cs.values():
            c.decompile()
            subrs = getattr(c.private, "Subrs", [])
            decompiler = _DehintingT2Decompiler(
                css,
                subrs,
                c.globalSubrs,
                c.private.nominalWidthX,
                c.private.defaultWidthX,
                c.private,
            )
            decompiler.execute(c)
            c.width = decompiler.width
        for charstring in css:
            _cs_drop_hints(charstring)
        del css

        # Drop font-wide hinting values
        all_privs = []
        if hasattr(font, "FDArray"):
            all_privs.extend(fd.Private for fd in font.FDArray)
        else:
            all_privs.append(font.Private)
        for priv in all_privs:
            for k in [
                "BlueValues",
                "OtherBlues",
                "FamilyBlues",
                "FamilyOtherBlues",
                "BlueScale",
                "BlueShift",
                "BlueFuzz",
                "StemSnapH",
                "StemSnapV",
                "StdHW",
                "StdVW",
                "ForceBold",
                "LanguageGroup",
                "ExpansionFactor",
            ]:
                if hasattr(priv, k):
                    setattr(priv, k, None)
    if removeUnusedSubrs:
        remove_unused_subroutines(cff)


def _pd_delete_empty_subrs(private_dict):
    if hasattr(private_dict, "Subrs") and not private_dict.Subrs:
        if "Subrs" in private_dict.rawDict:
            del private_dict.rawDict["Subrs"]
        del private_dict.Subrs


def remove_unused_subroutines(cff):
    for fontname in cff.keys():
        font = cff[fontname]
        cs = font.CharStrings
        # Renumber subroutines to remove unused ones

        # Mark all used subroutines
        for c in cs.values():
            subrs = getattr(c.private, "Subrs", [])
            decompiler = _MarkingT2Decompiler(subrs, c.globalSubrs, c.private)
            decompiler.execute(c)

        all_subrs = [font.GlobalSubrs]
        if hasattr(font, "FDArray"):
            all_subrs.extend(
                fd.Private.Subrs
                for fd in font.FDArray
                if hasattr(fd.Private, "Subrs") and fd.Private.Subrs
            )
        elif hasattr(font.Private, "Subrs") and font.Private.Subrs:
            all_subrs.append(font.Private.Subrs)

        subrs = set(subrs)  # Remove duplicates

        # Prepare
        for subrs in all_subrs:
            if not hasattr(subrs, "_used"):
                subrs._used = set()
            subrs._used = _uniq_sort(subrs._used)
            subrs._old_bias = calcSubrBias(subrs)
            subrs._new_bias = calcSubrBias(subrs._used)

        # Renumber glyph charstrings
        for c in cs.values():
            subrs = getattr(c.private, "Subrs", None)
            _cs_subset_subroutines(c, subrs, font.GlobalSubrs)

        # Renumber subroutines themselves
        for subrs in all_subrs:
            if subrs == font.GlobalSubrs:
                if not hasattr(font, "FDArray") and hasattr(font.Private, "Subrs"):
                    local_subrs = font.Private.Subrs
                elif (
                    hasattr(font, "FDArray")
                    and len(font.FDArray) == 1
                    and hasattr(font.FDArray[0].Private, "Subrs")
                ):
                    # Technically we shouldn't do this. But I've run into fonts that do it.
                    local_subrs = font.FDArray[0].Private.Subrs
                else:
                    local_subrs = None
            else:
                local_subrs = subrs

            subrs.items = [subrs.items[i] for i in subrs._used]
            if hasattr(subrs, "file"):
                del subrs.file
            if hasattr(subrs, "offsets"):
                del subrs.offsets

            for subr in subrs.items:
                _cs_subset_subroutines(subr, local_subrs, font.GlobalSubrs)

        # Delete local SubrsIndex if empty
        if hasattr(font, "FDArray"):
            for fd in font.FDArray:
                _pd_delete_empty_subrs(fd.Private)
        else:
            _pd_delete_empty_subrs(font.Private)

        # Cleanup
        for subrs in all_subrs:
            del subrs._used, subrs._old_bias, subrs._new_bias
</file>

<file path="width.py">
# -*- coding: utf-8 -*-

"""T2CharString glyph width optimizer.

CFF glyphs whose width equals the CFF Private dictionary's ``defaultWidthX``
value do not need to specify their width in their charstring, saving bytes.
This module determines the optimum ``defaultWidthX`` and ``nominalWidthX``
values for a font, when provided with a list of glyph widths."""

from fontTools.ttLib import TTFont
from collections import defaultdict
from operator import add
from functools import reduce


__all__ = ["optimizeWidths", "main"]


class missingdict(dict):
    def __init__(self, missing_func):
        self.missing_func = missing_func

    def __missing__(self, v):
        return self.missing_func(v)


def cumSum(f, op=add, start=0, decreasing=False):
    keys = sorted(f.keys())
    minx, maxx = keys[0], keys[-1]

    total = reduce(op, f.values(), start)

    if decreasing:
        missing = lambda x: start if x > maxx else total
        domain = range(maxx, minx - 1, -1)
    else:
        missing = lambda x: start if x < minx else total
        domain = range(minx, maxx + 1)

    out = missingdict(missing)

    v = start
    for x in domain:
        v = op(v, f[x])
        out[x] = v

    return out


def byteCost(widths, default, nominal):
    if not hasattr(widths, "items"):
        d = defaultdict(int)
        for w in widths:
            d[w] += 1
        widths = d

    cost = 0
    for w, freq in widths.items():
        if w == default:
            continue
        diff = abs(w - nominal)
        if diff <= 107:
            cost += freq
        elif diff <= 1131:
            cost += freq * 2
        else:
            cost += freq * 5
    return cost


def optimizeWidthsBruteforce(widths):
    """Bruteforce version.  Veeeeeeeeeeeeeeeeery slow.  Only works for smallests of fonts."""

    d = defaultdict(int)
    for w in widths:
        d[w] += 1

    # Maximum number of bytes using default can possibly save
    maxDefaultAdvantage = 5 * max(d.values())

    minw, maxw = min(widths), max(widths)
    domain = list(range(minw, maxw + 1))

    bestCostWithoutDefault = min(byteCost(widths, None, nominal) for nominal in domain)

    bestCost = len(widths) * 5 + 1
    for nominal in domain:
        if byteCost(widths, None, nominal) > bestCost + maxDefaultAdvantage:
            continue
        for default in domain:
            cost = byteCost(widths, default, nominal)
            if cost < bestCost:
                bestCost = cost
                bestDefault = default
                bestNominal = nominal

    return bestDefault, bestNominal


def optimizeWidths(widths):
    """Given a list of glyph widths, or dictionary mapping glyph width to number of
    glyphs having that, returns a tuple of best CFF default and nominal glyph widths.

    This algorithm is linear in UPEM+numGlyphs."""

    if not hasattr(widths, "items"):
        d = defaultdict(int)
        for w in widths:
            d[w] += 1
        widths = d

    keys = sorted(widths.keys())
    minw, maxw = keys[0], keys[-1]
    domain = list(range(minw, maxw + 1))

    # Cumulative sum/max forward/backward.
    cumFrqU = cumSum(widths, op=add)
    cumMaxU = cumSum(widths, op=max)
    cumFrqD = cumSum(widths, op=add, decreasing=True)
    cumMaxD = cumSum(widths, op=max, decreasing=True)

    # Cost per nominal choice, without default consideration.
    nomnCostU = missingdict(
        lambda x: cumFrqU[x] + cumFrqU[x - 108] + cumFrqU[x - 1132] * 3
    )
    nomnCostD = missingdict(
        lambda x: cumFrqD[x] + cumFrqD[x + 108] + cumFrqD[x + 1132] * 3
    )
    nomnCost = missingdict(lambda x: nomnCostU[x] + nomnCostD[x] - widths[x])

    # Cost-saving per nominal choice, by best default choice.
    dfltCostU = missingdict(
        lambda x: max(cumMaxU[x], cumMaxU[x - 108] * 2, cumMaxU[x - 1132] * 5)
    )
    dfltCostD = missingdict(
        lambda x: max(cumMaxD[x], cumMaxD[x + 108] * 2, cumMaxD[x + 1132] * 5)
    )
    dfltCost = missingdict(lambda x: max(dfltCostU[x], dfltCostD[x]))

    # Combined cost per nominal choice.
    bestCost = missingdict(lambda x: nomnCost[x] - dfltCost[x])

    # Best nominal.
    nominal = min(domain, key=lambda x: bestCost[x])

    # Work back the best default.
    bestC = bestCost[nominal]
    dfltC = nomnCost[nominal] - bestCost[nominal]
    ends = []
    if dfltC == dfltCostU[nominal]:
        starts = [nominal, nominal - 108, nominal - 1132]
        for start in starts:
            while cumMaxU[start] and cumMaxU[start] == cumMaxU[start - 1]:
                start -= 1
            ends.append(start)
    else:
        starts = [nominal, nominal + 108, nominal + 1132]
        for start in starts:
            while cumMaxD[start] and cumMaxD[start] == cumMaxD[start + 1]:
                start += 1
            ends.append(start)
    default = min(ends, key=lambda default: byteCost(widths, default, nominal))

    return default, nominal


def main(args=None):
    """Calculate optimum defaultWidthX/nominalWidthX values"""

    import argparse

    parser = argparse.ArgumentParser(
        "fonttools cffLib.width",
        description=main.__doc__,
    )
    parser.add_argument(
        "inputs", metavar="FILE", type=str, nargs="+", help="Input TTF files"
    )
    parser.add_argument(
        "-b",
        "--brute-force",
        dest="brute",
        action="store_true",
        help="Use brute-force approach (VERY slow)",
    )

    args = parser.parse_args(args)

    for fontfile in args.inputs:
        font = TTFont(fontfile)
        hmtx = font["hmtx"]
        widths = [m[0] for m in hmtx.metrics.values()]
        if args.brute:
            default, nominal = optimizeWidthsBruteforce(widths)
        else:
            default, nominal = optimizeWidths(widths)
        print(
            "glyphs=%d default=%d nominal=%d byteCost=%d"
            % (len(widths), default, nominal, byteCost(widths, default, nominal))
        )


if __name__ == "__main__":
    import sys

    if len(sys.argv) == 1:
        import doctest

        sys.exit(doctest.testmod().failed)
    main()
</file>

</files>
