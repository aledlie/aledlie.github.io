# Cover Letter: Anthropic

**Policy Team Application**

---

**Isabel Budenz**
Fuchsstraße
+31 (0)630639949
isabelbudenz@hotmail.com

---

[Date]

Anthropic
Policy Team
[San Francisco / London]

Dear Anthropic Policy Team,

I am writing to express my strong interest in joining Anthropic's Policy team. Your recent commitment to [signing the EU's General-Purpose AI Code of Practice](https://www.anthropic.com/news/eu-code-practice)—and your statement that the Code "advances the principles of transparency, safety and accountability" that Anthropic has long championed—reflects precisely why I want to work here. As an LLM candidate in International Commercial Arbitration with specialized training in the EU AI Act and hands-on AI implementation experience at Integrity Studio, I can contribute directly to Anthropic's EU regulatory engagement and broader international policy work.

**Why Anthropic**

Anthropic describes itself as "equal parts research lab, policy think-tank, and technology startup." That synthesis is rare and, I believe, necessary. The AI governance challenges we face cannot be solved by technologists working in isolation from policy experts, or by regulators without deep technical understanding. Anthropic's commitment to building those bridges—through proactive policy engagement, Constitutional AI research, and transparent safety practices—is why I want to contribute to your work rather than somewhere else.

Your [case for targeted regulation](https://www.anthropic.com/news/the-case-for-targeted-regulation) resonated with me. The argument that effective AI governance requires precision—focusing on genuine risks rather than broad prohibitions—aligns with my own view developed through studying the EU AI Act. The Act's risk-based approach is directionally right, but implementation will determine whether it enables responsible innovation or creates compliance burdens that disadvantage safety-focused developers like Anthropic. I want to help ensure the former.

**What I Bring**

*EU AI Act Expertise—At a Critical Moment*

Anthropic is among the 5-15 companies globally subject to the enhanced requirements for frontier AI models under the EU AI Act. With GPAI obligations now in effect (August 2025) and full enforcement approaching, you need team members who understand both the regulatory requirements and how to translate them into operational practices.

My coursework on the EU AI Act gave me deep familiarity with:
- The GPAI model provider obligations Anthropic must meet
- Technical documentation and transparency reporting requirements
- The AI Office's enforcement approach and emerging guidance
- How the Code of Practice Anthropic signed will be interpreted and implemented

Critically, I can conduct this work across languages. As a native German and Spanish speaker with C2 English and working French, I can engage directly with regulators, review member state implementation guidance, and monitor policy developments across the EU's major jurisdictions—without relying on translation.

*International Law Foundation*

My legal training provides frameworks for thinking about AI governance that complement technical perspectives:

- **LLM in International Commercial Arbitration** (Stockholm University): Cross-border dispute resolution, jurisdictional complexity, enforcement mechanisms
- **LLB in International and European Law** (University of Groningen): EU institutional dynamics, fundamental rights frameworks, regulatory harmonization
- **Legal Researcher, A for Arbitration** (2019-2025): Rigorous research methodology, synthesizing complex materials, presenting findings to diverse audiences

International law teaches you to navigate situations where multiple legal systems with different values must coexist—exactly the challenge facing AI governance as the EU, US, UK, and other jurisdictions develop divergent approaches.

*Practical AI Implementation Experience*

At Integrity Studio, I worked on AI implementation for mission-driven organizations. [CUSTOMIZE: Add specific details—e.g., "I helped nonprofit clients evaluate AI tools against their values and operational needs, developing governance frameworks that enabled adoption while managing risks." / "I contributed to AI strategy assessments, translating technical capabilities into actionable recommendations for non-technical stakeholders."]

This experience taught me that the gap between policy on paper and implementation in practice is where most challenges arise. I understand how organizations actually adopt AI—the concerns, the constraints, the tradeoffs—which informs how I think about what makes regulation effective rather than merely well-intentioned.

**How I Would Contribute**

I am interested in roles where I can support Anthropic's policy engagement, particularly:

*EU Regulatory Affairs*
- Supporting compliance with GPAI model obligations and the Code of Practice
- Monitoring regulatory developments across EU member states
- Contributing to Anthropic's engagement with the AI Office and national authorities
- Preparing technical documentation and transparency materials

*International Policy Analysis*
- Tracking regulatory developments across jurisdictions
- Analyzing policy proposals and their implications for Anthropic
- Contributing to position papers and policy submissions
- Supporting engagement with policymakers and multi-stakeholder initiatives

*Stakeholder Engagement*
- Supporting partnerships with think tanks, academic institutions, and civil society
- Contributing to Anthropic's thought leadership in AI governance
- Helping communicate Anthropic's approach to diverse audiences

I am based in Europe and would be well-positioned to support Anthropic's London office and EU-focused work, though I am open to other arrangements depending on team needs.

**Why Now**

The next two years will be formative for AI governance. The EU AI Act is moving from legislation to implementation. The US is navigating federal-state tensions over AI regulation. International coordination efforts are accelerating. Anthropic's voice in these conversations matters—not just for the company, but for whether AI governance develops in ways that enable rather than hinder safety-focused development.

I want to contribute to that work. My legal training, EU regulatory expertise, multilingual capabilities, and practical AI experience position me to add value to your team from day one.

Thank you for considering my application. I would welcome the opportunity to discuss how I can contribute to Anthropic's policy mission.

Sincerely,

**Isabel Budenz**
LLM Candidate, International Commercial Arbitration
Stockholm University

---

## Attachments
- Curriculum Vitae
- Writing Sample: [EU AI Act analysis or policy memo]
- [Additional materials as requested]

---

# Why This Letter Works for Anthropic

## Alignment with Anthropic's Values

| Anthropic Value | How Letter Demonstrates Alignment |
|-----------------|----------------------------------|
| Safety-focused development | Frames EU AI Act as enabling responsible innovation |
| Proactive policy engagement | Emphasizes contributing to, not just complying with, governance |
| Transparency | Highlights documentation and stakeholder communication skills |
| Intellectual rigor | Legal training + research methodology |
| Mission-driven | Integrity Studio experience with values-aligned organizations |

## Addressing What Anthropic Needs Now

| Anthropic Need | Isabel's Contribution |
|----------------|----------------------|
| EU AI Act compliance (GPAI obligations) | Direct expertise from coursework |
| Code of Practice implementation | Understanding of framework + multilingual monitoring |
| International policy tracking | Legal training + 4-language capability |
| Stakeholder engagement | Research + communication experience |
| European presence | Based in Europe, London office fit |

## Tone Calibration

- **Intellectually serious**: References specific Anthropic publications and positions
- **Practically grounded**: Emphasizes implementation, not just theory
- **Mission-aligned**: Connects personal motivation to Anthropic's approach
- **Specific**: Names EU AI Act provisions, Code of Practice, timeline details
- **Humble but confident**: Acknowledges learning while showing clear value-add

---

# Customization Checklist

- [ ] Complete Integrity Studio paragraph with specific details
- [ ] Specify preferred location (San Francisco vs. London)
- [ ] Update writing sample title (ideally EU AI Act related)
- [ ] Check Anthropic careers page for specific open roles to reference
- [ ] Add any connections to current Anthropic employees

---

# Role-Specific Variations

## If Applying to "Policy Programs and Partnerships"

Add after "How I Would Contribute":

> "I am particularly drawn to the Policy Programs and Partnerships function, where I could contribute to developing strategic relationships with the think tanks, academic institutions, and civil society organizations that shape AI governance discourse. My experience at A for Arbitration—engaging with diverse stakeholders across the international arbitration community—prepared me for this kind of ecosystem-building work."

## If Applying to EU/UK-Specific Role

Add:

> "Based in Europe and familiar with both EU and UK regulatory environments, I am well-positioned to support Anthropic's regional policy engagement. I can monitor developments across multiple jurisdictions simultaneously, engage with regulators in their working languages, and help ensure Anthropic's voice is heard in the policy conversations that will shape AI governance in Europe."

## If Applying to Trust & Safety

Reframe contributions section:

> "My legal training in dispute resolution and my understanding of AI governance frameworks position me to contribute to Trust & Safety work—helping develop policies that anticipate harms, create accountability mechanisms, and ensure Claude's deployment aligns with Anthropic's safety commitments."

---

# Application Strategy

## Anthropic's Hiring Approach

Anthropic does not have a traditional internship program. Options include:

| Path | Details | Fit for Isabel |
|------|---------|----------------|
| **Direct application** | Apply to open Policy roles | Best if roles match experience level |
| **AI Safety Fellows** | 4-month research fellowship ($15K/month stipend) | More technical/research focused |
| **Networking** | Connect with Policy team members | Build relationships first |

## Recommended Approach

1. **Check [Anthropic Careers](https://www.anthropic.com/careers)** for current Policy openings
2. **Apply directly** if roles align with experience level
3. **Connect on LinkedIn** with Policy team members (introduce yourself, express interest)
4. **Engage with Anthropic's policy content** (comment thoughtfully on their publications)

## Key Contacts to Research

- Policy team leadership
- EU/UK policy specialists
- Anyone working on AI Act compliance
- Alumni from European law schools

---

# Anthropic-Specific Knowledge to Demonstrate

## In Interview, Reference:

1. **Constitutional AI**: Anthropic's approach to training AI systems to be helpful, harmless, and honest through self-supervision
2. **Responsible Scaling Policy**: Framework for responsible capability development
3. **EU Code of Practice commitment**: July 2025 announcement
4. **Case for targeted regulation**: Anthropic's policy position paper
5. **Claude's character**: Understanding of how Anthropic thinks about AI behavior

## Policy Positions to Know:

- Anthropic supports targeted, risk-based regulation over broad prohibitions
- Emphasizes transparency and external evaluation
- Advocates for government investment in AI safety research
- Supports technical standards development through multi-stakeholder processes

---

# Sources Referenced

- [Anthropic EU Code of Practice Announcement](https://www.anthropic.com/news/eu-code-practice)
- [The Case for Targeted Regulation](https://www.anthropic.com/news/the-case-for-targeted-regulation)
- [Anthropic Careers](https://www.anthropic.com/careers)
- [Policy Programs and Partnerships Role](https://jobs.menlovc.com/companies/anthropic/jobs/49968677-policy-programs-and-partnerships)

---

*Cover letter prepared January 2026 for Anthropic Policy Team*
